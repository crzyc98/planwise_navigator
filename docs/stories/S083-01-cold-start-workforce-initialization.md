# Story S083-01: Cold Start Workforce Initialization

## Story Overview

**Epic**: E027 - Multi-Year Simulation Reliability & Performance
**Points**: 5
**Priority**: High

### Key Improvements (Based on Gemini Analysis)
1. **Fixed chicken-and-egg problem**: Added table existence check using `adapter.get_relation` to handle truly empty databases
2. **Removed redundant orchestration**: Eliminated `bootstrap_workforce_if_needed` function; dbt models now handle all logic
3. **Improved performance**: Optimized queries using CROSS JOIN instead of repetitive subqueries
4. **Enhanced error handling**: Added simulation run log, schema compatibility checks, and better validation flow
5. **Added comprehensive tests**: Included idempotency, empty census, no active employees, and schema compatibility tests

### User Story
**As a** simulation analyst
**I want** multi-year simulations to work on fresh database instances
**So that** I can deploy reliably without pre-existing workforce state

### Problem Statement
Multi-year simulations fail on fresh database instances because `int_previous_year_workforce` expects prior year data that doesn't exist on cold starts. This causes subsequent simulation years to begin with an empty workforce, breaking the entire multi-year simulation pipeline.

### Root Cause
The workforce baseline preparation models (`int_baseline_workforce`, `int_previous_year_workforce`, `prepare_year_snapshot`) lack proper initialization logic for "year 0" scenarios, causing dependency failures when no prior workforce state exists.

---

## Acceptance Criteria

### Primary Acceptance Criteria
1. **Cold Start Success**: Multi-year simulations execute successfully on empty databases without manual intervention
2. **Workforce Baseline Seeding**: `int_baseline_workforce` properly initializes from census data on first run
3. **State Handoff**: Proper workforce state handoff between simulation years maintains continuity
4. **Graceful Fallback**: `int_previous_year_workforce` handles missing prior year data without errors
5. **Data Consistency**: Workforce continuity maintained across all simulation years with proper active employee counts

### Secondary Acceptance Criteria
1. **Error Handling**: Clear error messages for unrecoverable initialization failures
2. **Performance**: Cold start initialization completes within 30 seconds for 100K employees
3. **Validation**: Data quality checks ensure proper workforce state initialization
4. **Documentation**: Clear troubleshooting guide for cold start scenarios

---

## Technical Specifications

### Current Architecture Issues
```sql
-- PROBLEMATIC: Current int_previous_year_workforce model
-- Assumes prior year data always exists
CREATE OR REPLACE TABLE int_previous_year_workforce AS
SELECT *
FROM fct_workforce_snapshot
WHERE simulation_year = {{ var('current_year') - 1 }}  -- FAILS on cold start
```

### Proposed Solution Architecture

#### 1. Cold Start Detection Logic with Table Existence Check
```sql
-- models/intermediate/int_cold_start_detection.sql
{{ config(materialized='table') }}

-- Use macro to safely check if table exists
{% set workforce_snapshot_exists = adapter.get_relation(
    database=target.database,
    schema=target.schema,
    identifier='fct_workforce_snapshot'
) is not none %}

{% if workforce_snapshot_exists %}
WITH simulation_state AS (
    SELECT
        COUNT(*) as prior_year_count,
        MAX(simulation_year) as max_year
    FROM {{ ref('fct_workforce_snapshot') }}
    WHERE simulation_year < {{ var('current_year') }}
),
cold_start_flag AS (
    SELECT
        CASE
            WHEN prior_year_count = 0 OR max_year IS NULL THEN true
            ELSE false
        END as is_cold_start,
        COALESCE(max_year, 0) as last_completed_year
    FROM simulation_state
)
SELECT * FROM cold_start_flag
{% else %}
-- Table doesn't exist, this is definitely a cold start
SELECT
    true as is_cold_start,
    0 as last_completed_year
{% endif %}
```

#### 2. Robust Baseline Workforce Preparation
```sql
-- models/intermediate/int_baseline_workforce.sql
{{ config(
    materialized='table',
    indexes=[
        {'columns': ['simulation_year'], 'type': 'btree'},
        {'columns': ['employee_id', 'simulation_year'], 'type': 'btree'}
    ]
) }}

WITH cold_start_check AS (
    SELECT is_cold_start, last_completed_year
    FROM {{ ref('int_cold_start_detection') }}
),
census_baseline AS (
    -- Cold start: Initialize from census data
    SELECT
        employee_id,
        hire_date,
        termination_date,
        annual_salary,
        job_level,
        department,
        'ACTIVE' as employee_status,
        0 as simulation_year,
        hire_date as effective_date,
        true as is_from_census
    FROM {{ ref('stg_census_data') }}
    WHERE termination_date IS NULL
),
continuing_baseline AS (
    -- Continuing simulation: Use previous year's end state
    SELECT
        w.employee_id,
        w.hire_date,
        w.termination_date,
        w.annual_salary,
        w.job_level,
        w.department,
        w.employee_status,
        w.simulation_year,
        w.effective_date,
        false as is_from_census
    FROM {{ ref('fct_workforce_snapshot') }} w
    CROSS JOIN cold_start_check c
    WHERE w.simulation_year = c.last_completed_year
)
-- Use CROSS JOIN to avoid repetitive subqueries
SELECT
    b.employee_id,
    b.hire_date,
    b.termination_date,
    b.annual_salary,
    b.job_level,
    b.department,
    b.employee_status,
    b.simulation_year,
    b.effective_date,
    b.is_from_census,
    c.is_cold_start,
    c.last_completed_year
FROM census_baseline b
CROSS JOIN cold_start_check c
WHERE c.is_cold_start = true

UNION ALL

SELECT
    b.employee_id,
    b.hire_date,
    b.termination_date,
    b.annual_salary,
    b.job_level,
    b.department,
    b.employee_status,
    b.simulation_year,
    b.effective_date,
    b.is_from_census,
    c.is_cold_start,
    c.last_completed_year
FROM continuing_baseline b
CROSS JOIN cold_start_check c
WHERE c.is_cold_start = false
```

#### 3. Enhanced Previous Year Workforce Model
```sql
-- models/intermediate/int_previous_year_workforce.sql
{{ config(materialized='table') }}

WITH baseline_workforce AS (
    SELECT
        employee_id,
        hire_date,
        termination_date,
        annual_salary,
        job_level,
        department,
        employee_status,
        simulation_year,
        effective_date
    FROM {{ ref('int_baseline_workforce') }}
),
workforce_with_validation AS (
    SELECT
        *,
        COUNT(*) OVER () as total_employees,
        SUM(CASE WHEN employee_status = 'ACTIVE' THEN 1 ELSE 0 END) OVER () as active_employees
    FROM baseline_workforce
)
SELECT
    employee_id,
    hire_date,
    termination_date,
    annual_salary,
    job_level,
    department,
    employee_status,
    simulation_year,
    effective_date,
    total_employees,
    active_employees
FROM workforce_with_validation

-- Data quality validation
{{ post_hook("
    SELECT
        'cold_start_validation' as test_name,
        active_employees,
        total_employees,
        CASE
            WHEN active_employees = 0 THEN 'FAILED: No active employees in baseline'
            WHEN active_employees < total_employees * 0.8 THEN 'WARNING: Low active employee ratio'
            ELSE 'PASSED'
        END as validation_status
    FROM (
        SELECT DISTINCT active_employees, total_employees
        FROM " ~ this ~ "
    )
") }}
```

#### 4. Simulation Run Log for Tracking Completed Years
```sql
-- models/intermediate/int_simulation_run_log.sql
{{ config(
    materialized='incremental',
    unique_key='simulation_year',
    on_schema_change='fail'
) }}

-- Only insert when a simulation year completes successfully
SELECT
    {{ var('current_year') }} as simulation_year,
    CURRENT_TIMESTAMP as completion_timestamp,
    'COMPLETED' as run_status,
    COUNT(*) as total_employees_processed
FROM {{ ref('fct_workforce_snapshot') }}
WHERE simulation_year = {{ var('current_year') }}
HAVING COUNT(*) > 0  -- Ensure we actually processed employees

{% if is_incremental() %}
    AND {{ var('current_year') }} NOT IN (
        SELECT simulation_year FROM {{ this }}
    )
{% endif %}
```

#### 5. Year Snapshot Preparation Enhancement
```sql
-- models/intermediate/int_year_snapshot_preparation.sql
{{ config(materialized='table') }}

WITH previous_year_workforce AS (
    SELECT * FROM {{ ref('int_previous_year_workforce') }}
),
simulation_parameters AS (
    SELECT
        {{ var('current_year') }} as simulation_year,
        DATE('{{ var('simulation_start_date') }}') as simulation_start_date
),
prepared_snapshot AS (
    SELECT
        w.employee_id,
        w.hire_date,
        w.termination_date,
        w.annual_salary,
        w.job_level,
        w.department,
        w.employee_status,
        p.simulation_year,
        p.simulation_start_date as effective_date,
        -- Cold start indicators
        w.active_employees as baseline_active_count,
        w.total_employees as baseline_total_count
    FROM previous_year_workforce w
    CROSS JOIN simulation_parameters p
    WHERE w.employee_status = 'ACTIVE'
)
SELECT * FROM prepared_snapshot

-- Validation: Ensure we have active employees
{{ post_hook("
    INSERT INTO mon_data_quality_checks (
        check_name,
        check_timestamp,
        table_name,
        check_result,
        check_details
    )
    SELECT
        'cold_start_active_employees_check' as check_name,
        CURRENT_TIMESTAMP as check_timestamp,
        '" ~ this ~ "' as table_name,
        CASE
            WHEN COUNT(*) = 0 THEN 'FAILED'
            WHEN COUNT(*) < 100 THEN 'WARNING'
            ELSE 'PASSED'
        END as check_result,
        'Active employees in year snapshot: ' || COUNT(*) as check_details
    FROM " ~ this ~ "
") }}
```

### Python Helper Functions

#### Cold Start Validation Utility
```python
# orchestrator/utils/cold_start_validation.py
from typing import Dict, Any, List
import pandas as pd
from dagster import AssetExecutionContext, asset, multi_asset
from orchestrator.resources import DuckDBResource

def validate_workforce_initialization(
    context: AssetExecutionContext,
    duckdb: DuckDBResource,
    simulation_year: int
) -> Dict[str, Any]:
    """Validate workforce initialization after all models have run"""

    validation_checks = []

    with duckdb.get_connection() as conn:
        # Check active employee count
        active_count = conn.execute("""
            SELECT COUNT(*) as count
            FROM fct_workforce_snapshot
            WHERE simulation_year = ? AND employee_status = 'ACTIVE'
        """, [simulation_year]).fetchone()[0]

        validation_checks.append({
            "check_name": "active_employee_count",
            "passed": active_count > 0,
            "message": f"Active employees in year {simulation_year}: {active_count}"
        })

        # Check if workforce continuity is maintained
        if simulation_year > 1:
            continuity_check = conn.execute("""
                SELECT
                    COUNT(DISTINCT p.employee_id) as prev_year_active,
                    COUNT(DISTINCT c.employee_id) as curr_year_employees
                FROM fct_workforce_snapshot p
                LEFT JOIN fct_workforce_snapshot c ON p.employee_id = c.employee_id
                    AND c.simulation_year = ?
                WHERE p.simulation_year = ? - 1
                    AND p.employee_status = 'ACTIVE'
            """, [simulation_year, simulation_year]).fetchone()

            continuity_ratio = continuity_check[1] / continuity_check[0] if continuity_check[0] > 0 else 0
            validation_checks.append({
                "check_name": "workforce_continuity",
                "passed": continuity_ratio > 0.5,  # At least 50% continuity expected
                "message": f"Workforce continuity: {continuity_ratio:.2%} of previous year active employees"
            })

        # Check simulation run log
        run_logged = conn.execute("""
            SELECT COUNT(*) FROM int_simulation_run_log
            WHERE simulation_year = ?
        """, [simulation_year]).fetchone()[0] > 0

        validation_checks.append({
            "check_name": "simulation_run_logged",
            "passed": run_logged,
            "message": f"Simulation year {simulation_year} logged: {run_logged}"
        })

    all_passed = all(check["passed"] for check in validation_checks)

    return {
        "simulation_year": simulation_year,
        "validation_status": "PASSED" if all_passed else "FAILED",
        "checks": validation_checks,
        "active_employee_count": active_count
    }

def check_schema_compatibility(
    context: AssetExecutionContext,
    duckdb: DuckDBResource
) -> bool:
    """Check if census and workforce snapshot schemas are compatible"""

    with duckdb.get_connection() as conn:
        census_columns = conn.execute("""
            SELECT column_name, data_type
            FROM information_schema.columns
            WHERE table_name = 'stg_census_data'
            ORDER BY ordinal_position
        """).fetchall()

        snapshot_columns = conn.execute("""
            SELECT column_name, data_type
            FROM information_schema.columns
            WHERE table_name = 'fct_workforce_snapshot'
            AND column_name IN (
                'employee_id', 'hire_date', 'termination_date',
                'annual_salary', 'job_level', 'department'
            )
            ORDER BY column_name
        """).fetchall()

        # Verify critical columns match
        census_dict = {col[0]: col[1] for col in census_columns}
        snapshot_dict = {col[0]: col[1] for col in snapshot_columns}

        required_columns = ['employee_id', 'hire_date', 'annual_salary', 'job_level', 'department']

        for col in required_columns:
            if col not in census_dict:
                context.log.error(f"Missing required column '{col}' in census data")
                return False

            if col in snapshot_dict and census_dict[col] != snapshot_dict[col]:
                context.log.warning(
                    f"Data type mismatch for '{col}': census={census_dict[col]}, "
                    f"snapshot={snapshot_dict[col]}"
                )

        return True
```

### Integration with Dagster Pipeline

#### Enhanced Workforce Preparation Assets
```python
# orchestrator/assets/workforce_preparation.py
from dagster import asset, AssetExecutionContext, multi_asset, AssetOut, AssetIn
from orchestrator.resources import DuckDBResource, DbtResource
from orchestrator.utils.cold_start_validation import (
    validate_workforce_initialization,
    check_schema_compatibility
)

@asset(
    deps=["stg_census_data"],
    description="Run dbt models for workforce baseline preparation"
)
def workforce_baseline_models(
    context: AssetExecutionContext,
    duckdb: DuckDBResource,
    dbt: DbtResource
) -> None:
    """Run all workforce baseline preparation models"""

    # First check schema compatibility
    if not check_schema_compatibility(context, duckdb):
        raise Exception("Schema compatibility check failed between census and workforce tables")

    # Run dbt models in correct order
    dbt_models = [
        "int_cold_start_detection",
        "int_baseline_workforce",
        "int_previous_year_workforce",
        "int_year_snapshot_preparation"
    ]

    context.log.info(f"Running workforce baseline models: {', '.join(dbt_models)}")
    dbt_results = dbt.run(dbt_models)

    if not dbt_results.success:
        raise Exception(f"dbt model execution failed: {dbt_results.results}")

@asset(
    deps=["workforce_baseline_models"],
    description="Validate workforce initialization after all models complete"
)
def workforce_initialization_validation(
    context: AssetExecutionContext,
    duckdb: DuckDBResource
) -> Dict[str, Any]:
    """Validate workforce initialization after all models have run"""

    simulation_year = context.run.run_config.get("simulation_year", 1)

    # Perform comprehensive validation
    validation_result = validate_workforce_initialization(context, duckdb, simulation_year)

    # Log validation results
    context.log.info(f"Workforce initialization validation: {validation_result['validation_status']}")
    for check in validation_result["checks"]:
        log_method = context.log.info if check["passed"] else context.log.warning
        log_method(f"  - {check['check_name']}: {check['message']}")

    if validation_result["validation_status"] == "FAILED":
        raise Exception(
            f"Workforce initialization validation failed for year {simulation_year}. "
            f"Failed checks: {[c['check_name'] for c in validation_result['checks'] if not c['passed']]}"
        )

    return validation_result

@asset(
    ins={"validation": AssetIn("workforce_initialization_validation")},
    description="Return validated workforce data for downstream processing"
)
def validated_workforce_baseline(
    context: AssetExecutionContext,
    duckdb: DuckDBResource,
    validation: Dict[str, Any]
) -> pd.DataFrame:
    """Return validated workforce baseline data"""

    simulation_year = context.run.run_config.get("simulation_year", 1)

    with duckdb.get_connection() as conn:
        workforce_df = conn.execute("""
            SELECT
                employee_id,
                hire_date,
                termination_date,
                annual_salary,
                job_level,
                department,
                employee_status,
                effective_date
            FROM int_baseline_workforce
            WHERE employee_status = 'ACTIVE'
        """).df()

    context.log.info(
        f"Returning validated workforce baseline with {len(workforce_df)} active employees"
    )

    return workforce_df
```

---

## Implementation Plan

### Phase 1: Detection and Validation (2 days)
1. Create `int_cold_start_detection` model
2. Add validation logic to existing workforce models
3. Implement Python helper functions for validation
4. Add comprehensive logging for cold start scenarios

### Phase 2: Baseline Workforce Enhancement (2 days)
1. Update `int_baseline_workforce` with conditional logic
2. Enhance `int_previous_year_workforce` with fallback handling
3. Add data quality checks and validation hooks
4. Test with fresh database instances

### Phase 3: Integration and Testing (1 day)
1. Update Dagster assets with cold start logic
2. Add error handling and recovery mechanisms
3. Create comprehensive test scenarios
4. Validate against existing multi-year simulations

---

## Testing Strategy

### Unit Tests
```python
# tests/test_cold_start_initialization.py
import pytest
from orchestrator.utils.cold_start_validation import validate_workforce_initialization, check_schema_compatibility
from dagster import build_asset_context

def test_cold_start_with_active_employees(duckdb_resource):
    """Test cold start validation with active employees"""
    # Setup: Create census data with active employees
    with duckdb_resource.get_connection() as conn:
        conn.execute("""
            INSERT INTO stg_census_data VALUES
                ('EMP001', '2020-01-01', NULL, 75000, 'L2', 'Engineering', 'FTE'),
                ('EMP002', '2020-01-01', NULL, 65000, 'L1', 'Marketing', 'FTE')
        """)
        conn.execute("""
            INSERT INTO fct_workforce_snapshot
            SELECT *, 1 as simulation_year, '2024-01-01' as effective_date
            FROM stg_census_data WHERE termination_date IS NULL
        """)

    # Execute: Run validation
    context = build_asset_context()
    result = validate_workforce_initialization(context, duckdb_resource, 1)

    # Assert: Validation passes with expected active count
    assert result["validation_status"] == "PASSED"
    assert result["active_employee_count"] == 2

def test_cold_start_with_empty_census(duckdb_resource):
    """Test cold start validation with empty census data"""
    # Setup: Ensure census table exists but is empty
    with duckdb_resource.get_connection() as conn:
        conn.execute("DELETE FROM stg_census_data")

    # Execute & Assert: Should fail gracefully
    context = build_asset_context()
    result = validate_workforce_initialization(context, duckdb_resource, 1)

    assert result["validation_status"] == "FAILED"
    assert result["active_employee_count"] == 0

def test_cold_start_no_active_employees(duckdb_resource):
    """Test when census has only terminated employees"""
    # Setup: Create census with only terminated employees
    with duckdb_resource.get_connection() as conn:
        conn.execute("""
            INSERT INTO stg_census_data VALUES
                ('EMP001', '2020-01-01', '2023-12-31', 75000, 'L2', 'Engineering', 'FTE'),
                ('EMP002', '2020-01-01', '2023-06-30', 65000, 'L1', 'Marketing', 'FTE')
        """)

    # Execute & Assert: Should fail with no active employees
    context = build_asset_context()
    result = validate_workforce_initialization(context, duckdb_resource, 1)

    assert result["validation_status"] == "FAILED"
    assert result["active_employee_count"] == 0

def test_idempotency_first_year(duckdb_resource):
    """Test that running year 1 twice produces same results"""
    # Setup: Run year 1 simulation
    with duckdb_resource.get_connection() as conn:
        conn.execute("""
            INSERT INTO stg_census_data VALUES
                ('EMP001', '2020-01-01', NULL, 75000, 'L2', 'Engineering', 'FTE')
        """)

        # First run
        conn.execute("""
            INSERT INTO fct_workforce_snapshot
            SELECT *, 1 as simulation_year, '2024-01-01' as effective_date
            FROM stg_census_data WHERE termination_date IS NULL
        """)
        first_count = conn.execute("SELECT COUNT(*) FROM fct_workforce_snapshot WHERE simulation_year = 1").fetchone()[0]

        # Second run (should not duplicate)
        conn.execute("""
            INSERT INTO fct_workforce_snapshot
            SELECT *, 1 as simulation_year, '2024-01-01' as effective_date
            FROM stg_census_data WHERE termination_date IS NULL
            ON CONFLICT DO NOTHING
        """)
        second_count = conn.execute("SELECT COUNT(*) FROM fct_workforce_snapshot WHERE simulation_year = 1").fetchone()[0]

    assert first_count == second_count, "Running year 1 twice should not duplicate data"

def test_schema_compatibility_check(duckdb_resource):
    """Test schema compatibility detection"""
    context = build_asset_context()

    # Test with compatible schemas
    assert check_schema_compatibility(context, duckdb_resource) == True

    # Test with missing column
    with duckdb_resource.get_connection() as conn:
        conn.execute("ALTER TABLE stg_census_data DROP COLUMN job_level")

    assert check_schema_compatibility(context, duckdb_resource) == False
```

### Integration Tests
```python
# tests/integration/test_multi_year_cold_start.py
def test_multi_year_simulation_cold_start(fresh_database):
    """Test complete multi-year simulation on fresh database"""
    # Setup: Fresh database with census data only
    # Execute: Run 3-year simulation
    # Assert: All years complete successfully with active employees

def test_workforce_continuity_across_years(fresh_database):
    """Test workforce state continuity across simulation years"""
    # Setup: Fresh database with census data
    # Execute: Run multi-year simulation
    # Assert: Workforce state maintains continuity across years
```

---

## Performance Requirements

| Metric | Target | Measurement |
|--------|--------|-------------|
| Cold Start Initialization | <30 seconds | Time to complete baseline workforce preparation |
| Active Employee Count | >0 in all years | Validation check for workforce continuity |
| Memory Usage | <2GB | Memory consumption during initialization |
| Data Quality | 100% pass rate | Validation checks for workforce state |

---

## Risk Assessment

### High Risk
- **Complex workforce state transitions**: Ensuring proper handoff between years
- **Data consistency**: Maintaining workforce integrity across cold starts

### Medium Risk
- **Performance impact**: Cold start logic may slow initialization
- **Edge cases**: Handling unusual census data scenarios

### Mitigation Strategies
- Comprehensive testing with various data scenarios
- Gradual rollout with monitoring and rollback capability
- Clear error messages and recovery procedures

---

## Definition of Done

### Functional Requirements
- [ ] Multi-year simulations execute successfully on fresh databases
- [ ] Workforce baseline properly seeds from census data on cold starts
- [ ] State handoff between years maintains workforce continuity
- [ ] Missing prior year data handled gracefully without errors
- [ ] Data quality validation ensures proper workforce initialization

### Technical Requirements
- [ ] Cold start detection logic implemented and tested
- [ ] Enhanced workforce preparation models deployed
- [ ] Python helper functions for validation and bootstrap
- [ ] Comprehensive error handling and logging
- [ ] Integration with existing Dagster pipeline

### Quality Requirements
- [ ] Unit tests for all cold start scenarios
- [ ] Integration tests for multi-year simulations
- [ ] Performance benchmarks met (<30 seconds initialization)
- [ ] Documentation updated with troubleshooting guide
- [ ] Code review completed and approved
