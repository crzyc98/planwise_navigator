# filename: docs/backlog.csv
epic_id,epic_name,story_id,story_title,description,acceptance_criteria,story_points,priority,sprint,status
E001,Core Data Pipeline,S001,Create dbt staging models,Build staging models for census and config data,"1. All source tables have staging models
2. Data types are properly cast
3. Basic data quality tests pass",5,Must Have,1,Complete
E001,Core Data Pipeline,S002,Build intermediate models,Create intermediate transformation models,"1. Hazard calculations implemented
2. Event generation logic works
3. Unit tests pass",8,Must Have,1,Complete
E001,Core Data Pipeline,S003,Create mart models,Build final analytical models,"1. All metrics calculated correctly
2. Performance < 30s for 10k employees
3. Documentation complete",5,Must Have,2,Complete
E001,Core Data Pipeline,S004,Add dbt tests,Comprehensive testing suite,"1. Unique/not null tests on keys
2. Relationship tests
3. Business logic tests",3,Must Have,2,Complete
E002,Orchestration Layer,S005,Setup Dagster project,Initialize Dagster with resources,"1. Project structure created
2. DuckDB resource configured
3. Basic asset defined",3,Must Have,1,Complete
E002,Orchestration Layer,S006,Create simulation assets,Build core simulation assets,"1. Config loading asset
2. Single year simulation
3. Multi-year orchestration",8,Must Have,2,Complete
E002,Orchestration Layer,S007,Add monitoring,Implement run monitoring,"1. Asset health checks
2. Failure alerts configured
3. Performance tracking",5,Nice to Have,6,Deferred
E003,User Interface,S008,Streamlit app skeleton,Basic dashboard structure,"1. Multi-page layout
2. Sidebar configuration
3. Basic styling applied",3,Must Have,2,Not Started
E003,User Interface,S009,Executive summary page,Build executive dashboard,"1. Key metrics displayed
2. Headcount projection chart
3. Responsive layout",5,Must Have,3,Not Started
E003,User Interface,S010,Workforce analysis page,Detailed workforce views,"1. Level distribution charts
2. Event analysis
3. Drill-down capability",5,Must Have,3,Not Started
E003,User Interface,S011,Financial impact page,Financial projections view,"1. Compensation charts
2. Cost breakdowns
3. Export functionality",5,Must Have,4,Not Started
E003,User Interface,S012,Scenario planning,Scenario comparison feature,"1. Multiple scenario support
2. Side-by-side comparison
3. Sensitivity analysis",8,Should Have,4,Not Started
E003,User Interface,S013,Report generation,PDF/Excel report creation,"1. Template rendering works
2. Charts included in PDF
3. Data export to Excel",5,Should Have,5,Not Started
E004,Data Quality & Validation,S014,Input validation,Validate census data quality,"1. Schema validation
2. Business rule checks
3. Error reporting",5,Must Have,1,Not Started
E004,Data Quality & Validation,S015,Reconciliation reports,Legacy vs new comparison,"1. Daily reconciliation runs
2. Variance reporting
3. Alert on >2% difference",5,Must Have,3,Not Started
E004,Data Quality & Validation,S016,Data lineage tracking,Track data transformations,"1. Column-level lineage
2. Transformation documentation
3. Impact analysis",3,Nice to Have,6,Not Started
E005,Performance & Scale,S017,Benchmark suite,Performance testing framework,"1. Automated benchmarks
2. Regression detection
3. Scale testing to 100k",5,Should Have,4,Not Started
E005,Performance & Scale,S018,Query optimization,Optimize slow queries,"1. Identify bottlenecks
2. Add appropriate indexes
3. <2s response time",5,Should Have,5,Not Started
E005,Performance & Scale,S019,Caching layer,Add results caching,"1. Redis/memory cache
2. Invalidation logic
3. Cache hit tracking",5,Nice to Have,6,Not Started
E006,Security & Compliance,S020,PII masking,Implement data masking,"1. Masking functions work
2. Role-based unmasking
3. Export protection",8,Must Have,4,Not Started
E006,Security & Compliance,S021,Audit logging,Comprehensive audit trail,"1. All data access logged
2. User actions tracked
3. Retention policy",5,Must Have,5,Not Started
E006,Security & Compliance,S022,Access control,Role-based permissions,"1. User roles defined
2. Permission checks
3. UI elements hidden",5,Should Have,5,Not Started
E007,Integration & Migration,S023,Legacy data import,ETL from legacy system,"1. All tables mapped
2. Data quality preserved
3. < 5 min runtime",8,Must Have,1,Not Started
E007,Integration & Migration,S024,Export capabilities,Data export features,"1. CSV/Excel export
2. API endpoint
3. Scheduled exports",5,Should Have,4,Not Started
E007,Integration & Migration,S025,API development,REST API for data access,"1. OpenAPI spec
2. Authentication
3. Rate limiting",8,Nice to Have,6,Not Started
E008,Documentation & Training,S026,User documentation,End-user guide,"1. All features documented
2. Screenshots included
3. FAQ section",3,Must Have,5,Not Started
E008,Documentation & Training,S027,Admin guide,System administration docs,"1. Installation steps
2. Configuration guide
3. Troubleshooting",3,Must Have,5,Not Started
E008,Documentation & Training,S028,Video tutorials,Training videos,"1. 5 feature videos
2. < 5 min each
3. Hosted solution",3,Nice to Have,6,Not Started
E009,Testing & QA,S029,Unit test coverage,Comprehensive unit tests,"1. >80% code coverage
2. All edge cases
3. Mocked dependencies",5,Must Have,3,Not Started
E009,Testing & QA,S030,Integration tests,End-to-end testing,"1. Happy path tests
2. Error scenarios
3. Performance tests",5,Must Have,4,Not Started
E009,Testing & QA,S031,UAT support,User acceptance testing,"1. Test scenarios
2. Issue tracking
3. Sign-off process",3,Must Have,5,Not Started
E010,DevOps & Deployment,S032,CI/CD pipeline,Automated deployment,"1. GitHub Actions setup
2. Test automation
3. Deploy to staging",5,Must Have,2,Not Started
E010,DevOps & Deployment,S033,Containerization,Docker deployment,"1. Dockerfile works
2. Docker Compose
3. <1GB image size",3,Should Have,3,Not Started
E010,DevOps & Deployment,S034,Monitoring setup,Production monitoring,"1. Prometheus metrics
2. Grafana dashboards
3. Alert rules",5,Should Have,6,Not Started
E011,Workforce Simulation Validation,S035,Workforce simulation data analysis,Analyze current simulation data to identify new hire status issues,"1. Query hire events from fct_yearly_events by year ✅
2. Trace new hire records through fct_workforce_snapshot pipeline ✅
3. Identify where employment_status becomes incorrect ✅
4. Document findings with SQL queries and data samples ✅
5. Create debugging dashboard/queries for validation ✅",5,Must Have,3,Complete
E011,Workforce Simulation Validation,S036,Fix new_hire_active classification,Fix employment status and classification logic for new hires,"1. New hires without termination show detailed_status_code = new_hire_active ✅
2. New hires with termination show detailed_status_code = new_hire_termination ✅
3. Employment status correctly set to active for non-terminated new hires ✅
4. Year extraction logic works correctly for hire date comparisons ✅
5. All existing functionality remains intact (no regressions) ✅",8,Must Have,3,Complete
E011,Workforce Simulation Validation,S037,Validate cumulative growth calculations,URGENT: Fix declining workforce (-7% to -12% annually instead of +3% growth),"1. Year-over-year active workforce growth matches 3% target (±0.5% tolerance) ✅
2. Cumulative growth calculation accounts for all previous year events ✅
3. Baseline workforce count correctly used for growth calculations ✅
4. Multi-year growth compounds correctly (not flat 3% each year) ✅
5. Growth validation tests pass for 5-year simulation ✅",5,Must Have,3,Complete
E011,Workforce Simulation Validation,S038,Fix workforce status determination,Review and fix workforce processing pipeline for consistent status,"1. All CTEs in fct_workforce_snapshot maintain correct employment status
2. New hire records preserve hire dates and status through transformations
3. Status transitions (active → terminated) work correctly for all employees
4. Deduplication logic preserves most accurate employee record
5. Previous year workforce correctly carries over active employees only",8,Must Have,3,Not Started
E011,Workforce Simulation Validation,S039,Add simulation validation tests,Create comprehensive test suite to validate simulation accuracy,"1. dbt tests validate all expected status codes present each year
2. Growth rate validation tests ensure targets met (±0.5% tolerance)
3. Termination rate tests validate against configuration parameters
4. Data quality tests check for NULLs duplicates and invalid states
5. End-to-end simulation tests validate 5-year projection accuracy",5,Must Have,3,Not Started
E011,Workforce Simulation Validation,S040,Create workforce metrics dashboard,Build validation dashboard to monitor simulation accuracy,"1. Real-time dashboard shows current simulation status by year
2. Workforce composition charts show all status categories
3. Growth rate tracking with target vs actual comparison
4. Termination rate monitoring with configuration benchmarks
5. Data quality indicators and validation status",3,Should Have,3,Not Started
E011,Workforce Simulation Validation,S041,Fix mathematical consistency between hiring and termination models,Align CEIL/ROUND logic between int_hiring_events.sql and int_termination_events.sql,"1. Both models use identical CEIL calculation for experienced terminations ✅
2. Hiring expectations exactly match actual termination generation ✅
3. Total_hires_needed formula uses consistent termination counts ✅
4. Growth calculations mathematically sound across all models ✅
5. No more formula mismatch between hiring and termination logic ✅",8,Must Have,3,Complete
E011,Workforce Simulation Validation,S042,Fix zero experienced terminations issue,Resolve int_termination_events.sql producing 0 terminations despite active workforce,"1. int_previous_year_workforce properly populated with simulation_year variable ✅
2. Termination quota applied to entire active_workforce instead of empty experienced_population ✅
3. Quota-first approach ensures reliable termination generation ✅
4. Target_terminations calculation produces expected counts (CEIL(workforce * 0.12)) ✅
5. Experienced terminations consistently generated across all simulation years ✅",8,Must Have,3,Complete
E011,Workforce Simulation Validation,S043,Fix employee ID uniqueness across simulation years,Prevent duplicate employee_id generation across different simulation years,"1. Employee ID format includes simulation year: NH_YYYY_XXXXXX ✅
2. No collisions possible between different simulation years ✅
3. All hire events have globally unique employee_id values ✅
4. New format maintains readability and structure ✅
5. Downstream models process unique IDs correctly ✅",5,Must Have,3,Complete
E011,Workforce Simulation Validation,S044,Fix Python orchestration logging and validation,Correct misleading termination logging and false formula mismatch warnings,"1. Python queries use correct event_category column for termination classification ✅
2. Experienced terminations logging shows actual counts not 0 ✅
3. Growth validation aligned with dbt target_ending_workforce_count formula ✅
4. False formula mismatch warnings eliminated ✅
5. Success messages shown when growth targets achieved ✅",5,Must Have,3,Complete
E012,Compensation System Integrity,S045,Diagnose compensation anomaly root cause,Investigate $18K average new hire compensation anomaly and trace through compensation calculation pipeline,"1. Query fct_yearly_events for hire compensation amounts by level_id
2. Identify Level 4/5 new hires with compensation > $500K
3. Trace compensation flow from config_job_levels → int_hiring_events → fct_workforce_snapshot
4. Document specific line numbers and calculations causing distortion
5. Create diagnostic queries for ongoing validation",3,Must Have,4,Not Started
E012,Compensation System Integrity,S046,Fix job levels configuration data,Correct extreme max_compensation values in config_job_levels.csv that create unrealistic salary calculations,"1. Level 4 max_compensation: 10000000 → 300000
2. Level 5 max_compensation: 15000000 → 500000
3. Compensation progression remains logical across all levels
4. No breaking changes to existing promotion/merit logic
5. Validate realistic avg_compensation calculations result",2,Must Have,4,Not Started
E012,Compensation System Integrity,S047,Fix compensation range calculation logic,Update int_hiring_events.sql to use capped max values in avg_compensation calculation,"1. avg_compensation uses capped max values for levels 4-5
2. Compensation assignment produces realistic new hire salaries ($60K-$350K range)
3. Level distribution maintains intended variance logic
4. No regression in lower level compensation calculations
5. Code follows existing patterns and style",5,Must Have,4,Not Started
E012,Compensation System Integrity,S048,Add compensation validation checks,Implement asset checks to prevent future compensation calculation errors,"1. Asset check: No hire events with compensation > $500K
2. Asset check: Average new hire compensation between $60K-$120K
3. Asset check: Compensation progression logical across levels 1-5
4. Asset check: Prorated compensation within reasonable bounds
5. Integration with existing Dagster monitoring",3,Must Have,4,Not Started
E012,Compensation System Integrity,S049,Validate compensation system end-to-end,Comprehensive testing of fixed compensation system across multi-year simulation,"1. New hire average compensation: $75K-$85K (validated across all levels)
2. Prorated compensation accurately reflects employment periods
3. No extreme outliers (>$500K) in any simulation year
4. Multi-year simulation maintains compensation consistency
5. Dashboard analytics show realistic compensation trends",5,Must Have,4,Not Started
