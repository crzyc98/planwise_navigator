#!/bin/bash
# CI/CD test suite for PlanWise Navigator
# Run this before committing any changes

set -e  # Exit on error

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Performance tracking
START_TIME=$(date +%s)
FAILED_TESTS=0
TOTAL_TESTS=0

# Function to log with timestamp and color
log_info() {
    echo -e "${BLUE}[$(date '+%H:%M:%S')]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[$(date '+%H:%M:%S')] ‚úÖ $1${NC}"
}

log_warning() {
    echo -e "${YELLOW}[$(date '+%H:%M:%S')] ‚ö†Ô∏è  $1${NC}"
}

log_error() {
    echo -e "${RED}[$(date '+%H:%M:%S')] ‚ùå $1${NC}"
    ((FAILED_TESTS++))
}

run_test() {
    local test_name="$1"
    local test_command="$2"
    local optional="${3:-false}"

    log_info "Running $test_name..."
    ((TOTAL_TESTS++))

    if eval "$test_command" > /tmp/ci_test_output 2>&1; then
        log_success "$test_name passed"
        return 0
    else
        if [ "$optional" = "true" ]; then
            log_warning "$test_name failed (optional test)"
            # Don't increment failed tests for optional tests
            ((FAILED_TESTS--))
        else
            log_error "$test_name failed"
            echo "Error output:"
            cat /tmp/ci_test_output | head -20
            echo "..."
            echo "Full output saved to /tmp/ci_test_output"
        fi
        return 1
    fi
}

# Header
echo -e "${BLUE}üîç Running PlanWise Navigator CI Tests...${NC}"
echo "========================================="

# Check if we're in the right directory
if [[ ! -f "CLAUDE.md" ]]; then
    log_error "Not in PlanWise Navigator root directory"
    echo "Please run from: /Users/nicholasamaral/planwise_navigator"
    exit 1
fi

# Activate virtual environment if it exists
if [[ -f "venv/bin/activate" ]]; then
    log_info "Activating virtual environment..."
    source venv/bin/activate
    log_success "Virtual environment activated"
else
    log_warning "Virtual environment not found - using system Python"
fi

# 1. Python validation
echo ""
log_info "üìù Python Code Quality Validation"
echo "================================="

# Check Python availability
if ! command -v python &> /dev/null; then
    log_error "Python not available"
    exit 1
fi

# Basic import check
run_test "Python import validation" "python -c 'import orchestrator, streamlit_dashboard'"

# Linting with available tools (relaxed for development)
if command -v ruff &> /dev/null; then
    # Focus on critical errors only, ignore unused imports and f-string placeholders for now
    run_test "Ruff linting (critical errors only)" "ruff check orchestrator/ streamlit_dashboard/ --select=E9,F63,F7,F82 --quiet"
elif command -v flake8 &> /dev/null; then
    run_test "Flake8 linting" "flake8 orchestrator/ streamlit_dashboard/ --max-line-length=88 --extend-ignore=E203,W503,F401"
elif command -v pylint &> /dev/null; then
    run_test "Pylint validation" "pylint orchestrator/ --fail-under=6.0 --disable=C0103,R0903,W0611"
else
    log_warning "No Python linting tools available (ruff, flake8, pylint)"
fi

# Type checking (optional for now)
if command -v mypy &> /dev/null; then
    run_test "Type checking" "mypy orchestrator/ --ignore-missing-imports" "true"
else
    log_warning "MyPy not available - skipping type checking"
fi

# 2. dbt validation
echo ""
log_info "üîß dbt Validation"
echo "================"

cd dbt

# Check dbt availability
if ! command -v dbt &> /dev/null; then
    log_error "dbt not available - install with: pip install dbt-core dbt-duckdb"
    exit 1
fi

# Install dbt dependencies
run_test "dbt dependencies" "dbt deps"

# Check compilation
run_test "dbt compilation" "dbt compile"

# Validate dbt contracts
log_info "üîí dbt contract validation..."
if dbt ls --select "tag:contract" > /dev/null 2>&1; then
    run_test "dbt contract validation" "dbt compile --select tag:contract"
    log_success "Contract-enabled models compiled successfully"
else
    log_warning "No contract-enabled models found"
fi

# Run fast tests (excluding slow ones) - optional since they depend on data
run_test "dbt fast tests" "dbt test --exclude tag:slow" "true"

# Critical model validation (optional - requires data)
log_info "üèóÔ∏è Running critical model validation..."
if dbt ls --select fct_workforce_snapshot fct_yearly_events dim_hazard_table > /dev/null 2>&1; then
    if run_test "Critical model run" "dbt run --select fct_workforce_snapshot fct_yearly_events dim_hazard_table --vars '{simulation_year: 2025}'"; then
        log_success "Critical models validated successfully"
    else
        log_warning "Critical model validation failed - may need data setup"
    fi
else
    log_warning "Critical models not found - skipping validation"
fi

# Data quality checks (optional)
if dbt ls --select dq_employee_id_validation > /dev/null 2>&1; then
    if run_test "Data quality validation" "dbt run --select dq_employee_id_validation --vars '{simulation_year: 2025}'"; then
        log_success "Data quality checks passed"
    else
        log_warning "Data quality checks failed - continuing..."
    fi
else
    log_warning "Data quality models not found - skipping validation"
fi

# 3. Additional validations
cd ..
echo ""
log_info "üß™ Additional Validations"
echo "========================"

# Check for common issues (optional)
run_test "Requirements file check" "pip check" "true"

# Check for security vulnerabilities if available
if command -v safety &> /dev/null; then
    run_test "Security vulnerability scan" "safety check"
else
    log_warning "Safety tool not available - skipping security scan"
fi

# Test configuration files
run_test "Configuration file validation" "python -c 'import yaml; yaml.safe_load(open(\"config/simulation_config.yaml\"))'"

# 4. Performance check
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

# 5. Final summary
echo ""
echo "üìä CI Test Summary:"
echo "==================="
echo -e "‚è±Ô∏è  Duration: ${DURATION}s"
echo -e "üìã Total tests: ${TOTAL_TESTS}"
echo -e "‚úÖ Passed: $((TOTAL_TESTS - FAILED_TESTS))"
echo -e "‚ùå Failed: ${FAILED_TESTS}"

if [ $FAILED_TESTS -eq 0 ]; then
    echo ""
    log_success "All CI tests passed! üéâ"
    echo ""
    echo "üí° Next steps:"
    echo "   - Review your changes one more time"
    echo "   - Run: git add . && git commit"
    echo "   - Push to remote repository"
    exit 0
else
    echo ""
    log_error "Some tests failed. Please fix the issues above before committing."
    echo ""
    echo "üîß Common fixes:"
    echo "   - For Python issues: Fix linting errors or update code"
    echo "   - For dbt issues: Check model syntax and dependencies"
    echo "   - For missing tools: pip install -r requirements-dev.txt"
    echo ""
    echo "üìñ For more help, check the project documentation"
    exit 1
fi
