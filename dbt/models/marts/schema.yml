version: 2

models:
  - name: dim_hazard_table
    description: "Master hazard dimension table with termination, promotion, and merit rates"
    config:
      tags: ["critical", "foundation"]
    columns:
      - name: year
        description: "Simulation year"
        data_tests:
          - not_null
      - name: level_id
        description: "Job level identifier"
        data_tests:
          - not_null
      - name: tenure_band
        description: "Employee tenure band"
        data_tests:
          - not_null
      - name: age_band
        description: "Employee age band"
        data_tests:
          - not_null
      - name: termination_rate
        description: "Annual termination probability"
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 0
          #     max_value: 1
      - name: promotion_rate
        description: "Annual promotion probability"
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 0
          #     max_value: 1
      - name: merit_raise
        description: "Annual merit increase percentage"
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 0
          #     max_value: 0.5

  - name: fct_employer_match_events
    description: >
      Employer match event generation model for integration with event sourcing architecture.
      Generates EMPLOYER_MATCH events from match calculations with full context and payload.
    config:
      tags: ["match_engine", "events", "critical"]
    columns:
      - name: event_id
        description: Unique event identifier
        data_tests:
          - not_null
          - unique
      - name: employee_id
        description: Employee receiving the match
        data_tests:
          - not_null
      - name: event_type
        description: Event type (always EMPLOYER_MATCH)
        data_tests:
          - not_null
          - accepted_values:
              values: ["EMPLOYER_MATCH"]
      - name: simulation_year
        description: Year of the match calculation
        data_tests:
          - not_null
      - name: amount
        description: Match amount
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 50000
      - name: event_payload
        description: JSON payload with match calculation details
        data_tests:
          - not_null
      - name: effective_date
        description: Date when match is applied (end of plan year)
        data_tests:
          - not_null

  - name: fct_yearly_events
    description: "Consolidated fact table of all workforce events by simulation year"
    config:
      tags: ["critical", "locked", "event_sourcing", "contract"]
    # Note: Removed dbt_utils.expression_is_true tests to prevent DuckDBRelation serialization issues
    # Basic data quality is validated through column-level tests below
    columns:
      - name: employee_id
        description: "Unique employee identifier"
        data_type: varchar
        data_tests:
          - not_null
      - name: employee_ssn
        description: "Employee SSN identifier"
        data_type: varchar
        data_tests:
          - not_null
      - name: event_type
        description: "Type of workforce event"
        data_type: varchar
        data_tests:
          - not_null
          - accepted_values:
              values: ['termination', 'promotion', 'hire', 'RAISE', 'enrollment', 'enrollment_change']
      - name: simulation_year
        description: "Year of simulation"
        data_type: integer
        data_tests:
          - not_null
      - name: effective_date
        description: "Date when event becomes effective"
        data_type: timestamp
        data_tests:
          - not_null
      - name: event_details
        description: "Detailed description of the event"
        data_type: varchar
      - name: compensation_amount
        description: "Compensation amount related to event"
        data_type: double
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 0
          #     max_value: 1000000
      - name: previous_compensation
        description: "Previous compensation amount before event"
        data_type: double
      - name: employee_age
        description: "Employee age at time of event"
        data_type: bigint
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 18
          #     max_value: 75
      - name: employee_tenure
        description: "Employee tenure at time of event"
        data_type: decimal(21,2)
      - name: level_id
        description: "Employee job level"
        data_type: integer
        data_tests:
          - not_null
          - accepted_values:
              values: [1, 2, 3, 4, 5]
      - name: age_band
        description: "Employee age band for analysis"
        data_type: varchar
      - name: tenure_band
        description: "Employee tenure band for analysis"
        data_type: varchar
      - name: event_probability
        description: "Probability associated with the event"
        data_type: double
      - name: event_category
        description: "Category of event for analysis"
        data_type: varchar
      - name: event_sequence
        description: "Sequence number for events within employee/year"
        data_type: bigint
        data_tests:
          - not_null
      - name: created_at
        description: "Timestamp when record was created"
        data_type: timestamp with time zone
      - name: parameter_scenario_id
        description: "Scenario ID for parameter tracking"
        data_type: varchar
      - name: parameter_source
        description: "Source of parameters used"
        data_type: varchar
      - name: data_quality_flag
        description: "Data quality validation flag"
        data_type: varchar
      - name: employee_deferral_rate
        description: "Employee's elected deferral percentage (0.00 to 0.75)"
        data_type: decimal(5,4)
      - name: prev_employee_deferral_rate
        description: "Previous deferral rate before change"
        data_type: decimal(5,4)
    data_tests:
      # Test that all simulation years are within reasonable bounds
      - dbt_utils.expression_is_true:
          expression: "simulation_year BETWEEN 2020 AND 2050"
          name: "simulation_year_within_bounds"
      # Test that compensation amounts are positive
      - dbt_utils.expression_is_true:
          expression: "compensation_amount >= 0"
          name: "compensation_positive_amounts"
      # Test that hire events have reasonable compensation (basic range check)
      - dbt_utils.expression_is_true:
          expression: "event_type != 'hire' OR compensation_amount BETWEEN 20000 AND 500000"
          name: "hire_compensation_reasonable_range"


  - name: fct_workforce_snapshot
    description: "Year-end workforce snapshot showing current state after all events"
    config:
      tags: ["critical", "foundation", "contract"]
    # Note: Removed dbt_utils.expression_is_true tests to prevent DuckDBRelation serialization issues
    # Basic data quality is validated through column-level tests below
    data_tests:
      # Test composite uniqueness: employee appears once per simulation year
      - unique:
          column_name: "employee_id || '_' || simulation_year"
          name: "unique_employee_per_simulation_year"
      # Test that simulation years are within reasonable bounds
      - dbt_utils.expression_is_true:
          expression: "simulation_year BETWEEN 2020 AND 2050"
          name: "workforce_simulation_year_bounds"
      # Test that active employees have positive compensation
      - dbt_utils.expression_is_true:
          expression: "employment_status != 'active' OR current_compensation > 0"
          name: "active_employees_have_compensation"
      # Test that detailed status codes align with employment status
      - dbt_utils.expression_is_true:
          expression: "(employment_status = 'active' AND detailed_status_code IN ('continuous_active', 'new_hire_active')) OR (employment_status = 'terminated' AND detailed_status_code IN ('experienced_termination', 'new_hire_termination'))"
          name: "status_codes_align_with_employment_status"
      # Test that tenure is reasonable relative to age
      - dbt_utils.expression_is_true:
          expression: "current_tenure <= (current_age - 16)"
          name: "tenure_reasonable_relative_to_age"
      # **NEW HIRE TERMINATION FIX TESTS**: Validate the core fix for new hire termination visibility
      # Test that new hire terminations have terminated employment status
      - dbt_utils.expression_is_true:
          expression: "detailed_status_code != 'new_hire_termination' OR employment_status = 'terminated'"
          name: "new_hire_terminations_marked_as_terminated"
      # Test that new hire terminations have termination dates
      - dbt_utils.expression_is_true:
          expression: "detailed_status_code != 'new_hire_termination' OR termination_date IS NOT NULL"
          name: "new_hire_terminations_have_termination_date"
      # Test that terminated employees hired in current year are classified as new_hire_termination
      - dbt_utils.expression_is_true:
          expression: "NOT (employment_status = 'terminated' AND EXTRACT(YEAR FROM employee_hire_date) = simulation_year) OR detailed_status_code = 'new_hire_termination'"
          name: "terminated_new_hires_classified_correctly"

      # CONTRIBUTION-SPECIFIC WORKFORCE VALIDATION TESTS

      # Critical: Contributions must not exceed compensation
      - dbt_utils.expression_is_true:
          expression: "prorated_annual_contributions <= (prorated_annual_compensation + 100)"
          name: "contributions_not_exceeding_compensation"
          meta:
            description: "Employee contributions must not exceed their compensation (with $100 tolerance)"
            priority: "P0"

      # Critical: IRS limited contributions must not exceed calculated contributions
      - dbt_utils.expression_is_true:
          expression: "irs_limited_annual_contributions <= prorated_annual_contributions"
          name: "irs_limited_contributions_logical"
          meta:
            description: "IRS limited contributions must not exceed calculated contributions"
            priority: "P0"

      # Critical: Excess contributions calculation accuracy
      - dbt_utils.expression_is_true:
          expression: "ABS((prorated_annual_contributions - irs_limited_annual_contributions) - excess_contributions) < 0.01"
          name: "excess_contributions_calculation_accuracy"
          meta:
            description: "Excess contributions must equal the difference between prorated and IRS limited (within $0.01)"
            priority: "P0"

      # Critical: IRS limit flag consistency
      - dbt_utils.expression_is_true:
          expression: "(excess_contributions > 0.01) = irs_limit_reached"
          name: "irs_limit_flag_consistency"
          meta:
            description: "IRS limit reached flag must be consistent with excess contributions"
            priority: "P0"

      # Critical: Age-based IRS limit application
      - dbt_utils.expression_is_true:
          expression: "(age_as_of_december_31 >= 50 AND applicable_irs_limit = 31000) OR (age_as_of_december_31 < 50 AND applicable_irs_limit = 23500)"
          name: "age_based_irs_limits_applied_correctly"
          meta:
            description: "Age-based IRS limits must be applied correctly (50+ gets catch-up)"
            priority: "P0"

      # Error: Non-enrolled employees should not have significant contributions
      - dbt_utils.expression_is_true:
          expression: "is_enrolled_flag = true OR prorated_annual_contributions <= 10"
          warn_if: ">0"
          name: "non_enrolled_should_not_contribute"
          meta:
            description: "Non-enrolled employees should not have significant contributions"
            priority: "P1"

      # Warning: High contribution rates monitoring
      - dbt_utils.expression_is_true:
          expression: "effective_deferral_rate <= 0.75"
          warn_if: ">10"
          name: "high_deferral_rates_monitoring"
          meta:
            description: "Monitor employees with very high deferral rates (>75%)"
            priority: "P2"

      # EMPLOYER MATCH-SPECIFIC VALIDATION TESTS

      # Critical: Employer match should be reasonable relative to employee contributions
      - dbt_utils.expression_is_true:
          expression: "employer_match_contribution <= (prorated_annual_contributions * 2)"
          name: "employer_match_reasonable_relative_to_contributions"
          meta:
            description: "Employer match should not exceed 2x employee contributions (generous limit)"
            priority: "P1"

      # Warning: Employees with match but no employee contributions (potential data issue)
      - dbt_utils.expression_is_true:
          expression: "employer_match_contribution <= 10 OR prorated_annual_contributions > 0"
          warn_if: ">5"
          name: "match_without_employee_contributions_monitoring"
          meta:
            description: "Monitor employees with employer match but no employee contributions"
            priority: "P2"

      # Critical: Non-enrolled employees should not have employer match
      - dbt_utils.expression_is_true:
          expression: "is_enrolled_flag = true OR employer_match_contribution <= 10"
          name: "non_enrolled_should_not_have_match"
          meta:
            description: "Non-enrolled employees should not have significant employer match"
            priority: "P1"
    columns:
      - name: employee_id
        description: "Unique employee identifier within simulation year"
        data_type: varchar
        data_tests:
          - not_null
      - name: employee_ssn
        description: "Employee SSN identifier"
        data_type: varchar
        data_tests:
          - not_null
      - name: employee_birth_date
        description: "Employee birth date"
        data_type: timestamp
      - name: employee_hire_date
        description: "Employee hire date"
        data_type: timestamp
      - name: current_compensation
        description: "Current annual compensation"
        data_type: double
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 0
          #     max_value: 1000000
      - name: prorated_annual_compensation
        description: "Prorated annual compensation based on actual time worked"
        data_type: double
      - name: full_year_equivalent_compensation
        description: "Full-year equivalent compensation eliminating proration effects"
        data_type: double
      - name: current_age
        description: "Current employee age"
        data_type: bigint
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 18
          #     max_value: 75
      - name: current_tenure
        description: "Current years of service"
        data_type: bigint
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 0
          #     max_value: 50
      - name: level_id
        description: "Current job level"
        data_type: integer
        data_tests:
          - not_null
          - accepted_values:
              values: [1, 2, 3, 4, 5]
      - name: age_band
        description: "Employee age band for analysis"
        data_type: varchar
      - name: tenure_band
        description: "Employee tenure band for analysis"
        data_type: varchar
      - name: employment_status
        description: "Current employment status"
        data_type: varchar
        data_tests:
          - not_null
          - accepted_values:
              values: ['active', 'terminated']
      - name: termination_date
        description: "Date of termination if applicable"
        data_type: timestamp
      - name: termination_reason
        description: "Reason for termination if applicable"
        data_type: varchar
      - name: detailed_status_code
        description: "Epic 11.5: Detailed status code categorizing employees into four cohorts"
        data_type: varchar
        data_tests:
          - not_null
          - accepted_values:
              values: ['continuous_active', 'experienced_termination', 'new_hire_active', 'new_hire_termination']
      - name: simulation_year
        description: "Simulation year for this snapshot"
        data_type: integer
        data_tests:
          - not_null
      - name: employee_eligibility_date
        description: "Date when employee becomes eligible for DC plan participation"
        data_type: date
      - name: waiting_period_days
        description: "Number of days employee must wait after hire to become eligible"
        data_type: integer
      - name: current_eligibility_status
        description: "Current eligibility status based on eligibility date and simulation year"
        data_type: varchar
        data_tests:
          - accepted_values:
              values: ['eligible', 'pending']
      - name: employee_enrollment_date
        description: "Date when employee enrolled in DC plan (from census data or enrollment events)"
        data_type: date
      - name: prorated_annual_contributions
        description: "Time-weighted annual employee contributions"
        data_type: double
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 50000
      - name: irs_limited_annual_contributions
        description: "Employee contributions after applying IRS 402(g) limits"
        data_type: double
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 31000
      - name: excess_contributions
        description: "Amount of contributions exceeding IRS limits"
        data_type: double
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 50000
      - name: effective_deferral_rate
        description: "Time-weighted effective deferral rate for the year"
        data_type: double
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 1.0
      - name: irs_limit_reached
        description: "Flag indicating if employee reached IRS contribution limits"
        data_type: boolean
        data_tests:
          - not_null
      - name: applicable_irs_limit
        description: "IRS contribution limit applicable to this employee"
        data_type: integer
        data_tests:
          - not_null
          - accepted_values:
              values: [23500, 31000]
      - name: age_as_of_december_31
        description: "Employee age as of December 31st for IRS limit determination"
        data_type: bigint
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 18
              max_value: 75
      - name: contribution_data_quality_flag
        description: "Data quality flag for contribution calculations"
        data_type: varchar
        data_tests:
          - not_null
          - accepted_values:
              values: ['VALID', 'NO_CONTRIBUTIONS', 'INVALID_EMPLOYEE_ID', 'CONTRIBUTIONS_EXCEED_COMPENSATION', 'IRS_LIMIT_MISMATCH', 'CONTRIBUTIONS_WITHOUT_ENROLLMENT', 'INVALID_DEFERRAL_RATE']
      - name: employer_match_contribution
        description: "Annual employer match contribution amount"
        data_type: double
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 50000
      - name: snapshot_created_at
        description: "Timestamp when snapshot was created"
        data_type: timestamp with time zone


  - name: fct_participant_balance_snapshots
    description: "Weekly participant balance snapshots for optimized DC plan queries - S072-06"
    config:
      tags: ["critical", "performance", "dc_plan", "contract"]
      contract:
        enforced: true
    data_tests:
      # Test composite uniqueness: participant appears once per plan per snapshot date
      - unique:
          column_name: "participant_id || '_' || plan_id || '_' || snapshot_date"
          name: "unique_participant_plan_snapshot"
      # Test that all balances are non-negative
      - dbt_utils.expression_is_true:
          expression: "total_employee_contributions >= 0 AND total_employer_contributions >= 0 AND gross_account_balance >= 0"
          name: "non_negative_balances"
      # Test vesting percentage constraints
      - dbt_utils.expression_is_true:
          expression: "current_vested_percentage BETWEEN 0.0000 AND 1.0000"
          name: "valid_vesting_percentage_range"
      # Test that vested balance <= gross balance
      - dbt_utils.expression_is_true:
          expression: "vested_account_balance <= gross_account_balance"
          name: "vested_balance_not_exceeding_gross"
      # Test that enrolled participants have enrollment dates
      - dbt_utils.expression_is_true:
          expression: "NOT is_enrolled OR enrollment_date IS NOT NULL"
          name: "enrolled_participants_have_enrollment_date"
      # Test snapshot date consistency (Fridays only)
      - dbt_utils.expression_is_true:
          expression: "EXTRACT(DAYOFWEEK FROM snapshot_date) = 6"  # Friday = 6 in DuckDB
          name: "snapshots_taken_on_fridays"
    columns:
      - name: participant_id
        description: "Unique participant identifier (employee_id)"
        data_type: varchar
        data_tests:
          - not_null
      - name: plan_id
        description: "DC plan identifier"
        data_type: varchar
        data_tests:
          - not_null
      - name: scenario_id
        description: "Simulation scenario identifier"
        data_type: varchar
        data_tests:
          - not_null
      - name: plan_design_id
        description: "Plan design configuration identifier"
        data_type: varchar
        data_tests:
          - not_null
      - name: snapshot_date
        description: "Weekly snapshot date (always Friday)"
        data_type: date
        data_tests:
          - not_null
      - name: total_employee_contributions
        description: "Cumulative employee contributions as of snapshot date"
        data_type: decimal(18,6)
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 1000000
      - name: total_employer_contributions
        description: "Cumulative employer contributions as of snapshot date"
        data_type: decimal(18,6)
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 1000000
      - name: total_forfeitures
        description: "Cumulative forfeiture amounts as of snapshot date"
        data_type: decimal(18,6)
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 1000000
      - name: gross_account_balance
        description: "Total account balance before forfeitures"
        data_type: decimal(18,6)
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 2000000
      - name: vested_account_balance
        description: "Vested portion of account balance"
        data_type: decimal(18,6)
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 2000000
      - name: unvested_balance
        description: "Unvested portion of employer contributions"
        data_type: decimal(18,6)
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 1000000
      - name: net_account_balance
        description: "Account balance after forfeitures"
        data_type: decimal(18,6)
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 2000000
      - name: current_vested_percentage
        description: "Current vesting percentage (0.0000 to 1.0000)"
        data_type: decimal(8,4)
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0.0000
              max_value: 1.0000
      - name: service_years
        description: "Years of service for vesting calculation"
        data_type: decimal(8,2)
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0.00
              max_value: 50.00
      - name: is_enrolled
        description: "Whether participant is enrolled in plan"
        data_type: boolean
        data_tests:
          - not_null
      - name: current_deferral_percentage
        description: "Current deferral percentage (0.0000 to 1.0000)"
        data_type: decimal(8,4)
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0.0000
              max_value: 1.0000
      - name: contribution_event_count
        description: "Number of contribution events as of snapshot"
        data_type: bigint
        data_tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 1000
      - name: eligibility_date
        description: "Date participant became eligible for plan"
        data_type: date
      - name: enrollment_date
        description: "Date participant enrolled in plan"
        data_type: date
      - name: participation_status
        description: "Detailed participation status classification"
        data_type: varchar
        data_tests:
          - not_null
          - accepted_values:
              values: ['active_participant', 'enrolled_zero_deferral', 'eligible_not_enrolled', 'not_eligible', 'unknown_status']
      - name: data_quality_flag
        description: "Data quality validation flag"
        data_type: varchar
        data_tests:
          - not_null
          - accepted_values:
              values: ['valid', 'negative_employee_balance', 'negative_employer_balance', 'invalid_vesting_percentage', 'enrolled_no_contributions', 'contributions_not_enrolled']
      - name: is_current_week
        description: "Flag indicating if this is current week snapshot"
        data_type: boolean
        data_tests:
          - not_null
      - name: snapshot_created_at
        description: "Timestamp when snapshot was created"
        data_type: timestamp with time zone
        data_tests:
          - not_null

  # Cross-model relationship tests
  - name: fct_compensation_growth
    description: "Compensation growth fact table validation"
    config:
      tags: ["critical"]
    data_tests:
      # Test that growth rates are within reasonable bounds (-50% to +50%)
      - dbt_utils.expression_is_true:
          expression: "yoy_growth_rate BETWEEN -0.5 AND 0.5"
          name: "compensation_growth_reasonable_bounds"
      # Test that simulation years are consistent
      - dbt_utils.expression_is_true:
          expression: "simulation_year BETWEEN 2020 AND 2050"
          name: "compensation_simulation_year_bounds"

# Note: Cross-table consistency tests are implemented in separate analysis models
# See data_quality_new_hire_termination_audit.sql and data_quality_event_sourcing_integrity.sql
