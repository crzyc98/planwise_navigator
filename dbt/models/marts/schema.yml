version: 2

models:
  - name: dim_hazard_table
    description: "Master hazard dimension table with termination, promotion, and merit rates"
    config:
      tags: ["critical", "foundation"]
    columns:
      - name: year
        description: "Simulation year"
        data_tests:
          - not_null
      - name: level_id
        description: "Job level identifier"
        data_tests:
          - not_null
      - name: tenure_band
        description: "Employee tenure band"
        data_tests:
          - not_null
      - name: age_band
        description: "Employee age band"
        data_tests:
          - not_null
      - name: termination_rate
        description: "Annual termination probability"
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 0
          #     max_value: 1
      - name: promotion_rate
        description: "Annual promotion probability"
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 0
          #     max_value: 1
      - name: merit_raise
        description: "Annual merit increase percentage"
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 0
          #     max_value: 0.5

  - name: fct_yearly_events
    description: "Consolidated fact table of all workforce events by simulation year"
    config:
      tags: ["critical", "locked", "event_sourcing", "contract"]
    # Note: Removed dbt_utils.expression_is_true tests to prevent DuckDBRelation serialization issues
    # Basic data quality is validated through column-level tests below
    columns:
      - name: employee_id
        description: "Unique employee identifier"
        data_type: varchar
        data_tests:
          - not_null
      - name: employee_ssn
        description: "Employee SSN identifier"
        data_type: varchar
        data_tests:
          - not_null
      - name: event_type
        description: "Type of workforce event"
        data_type: varchar
        data_tests:
          - not_null
          - accepted_values:
              values: ['termination', 'promotion', 'hire', 'RAISE', 'enrollment', 'enrollment_change', 'DEFERRAL_ESCALATION']
      - name: simulation_year
        description: "Year of simulation"
        data_type: integer
        data_tests:
          - not_null
      - name: effective_date
        description: "Date when event becomes effective"
        data_type: timestamp
        data_tests:
          - not_null
      - name: event_details
        description: "Detailed description of the event"
        data_type: varchar
      - name: compensation_amount
        description: "Compensation amount related to event"
        data_type: double
        # Temporarily disabled - some events (enrollment, deferral escalation) don't have compensation
      - name: previous_compensation
        description: "Previous compensation amount before event"
        data_type: double
      - name: employee_age
        description: "Employee age at time of event"
        data_type: bigint
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 18
          #     max_value: 75
      - name: employee_tenure
        description: "Employee tenure at time of event"
        data_type: decimal(21,2)
      - name: level_id
        description: "Employee job level"
        data_type: integer
        data_tests:
          - not_null
          - accepted_values:
              values: [1, 2, 3, 4, 5]
      - name: age_band
        description: "Employee age band for analysis"
        data_type: varchar
      - name: tenure_band
        description: "Employee tenure band for analysis"
        data_type: varchar
      - name: event_probability
        description: "Probability associated with the event"
        data_type: double
      - name: event_category
        description: "Category of event for analysis"
        data_type: varchar
      - name: event_sequence
        description: "Sequence number for events within employee/year"
        data_type: bigint
        data_tests:
          - not_null
      - name: created_at
        description: "Timestamp when record was created"
        data_type: timestamp with time zone
      - name: parameter_scenario_id
        description: "Scenario ID for parameter tracking"
        data_type: varchar
      - name: parameter_source
        description: "Source of parameters used"
        data_type: varchar
      - name: data_quality_flag
        description: "Data quality validation flag"
        data_type: varchar
      - name: employee_deferral_rate
        description: "Employee's elected deferral percentage (0.00 to 0.75)"
        data_type: decimal(5,4)
      - name: prev_employee_deferral_rate
        description: "Previous deferral rate before change"
        data_type: decimal(5,4)
    # data_tests disabled for dbt 1.8.8 compatibility


  - name: fct_workforce_snapshot
    description: "Year-end workforce snapshot showing current state after all events"
    config:
      tags: ["critical", "foundation", "contract"]
    # Note: Removed dbt_utils.expression_is_true tests to prevent DuckDBRelation serialization issues
    # Basic data quality is validated through column-level tests below
    data_tests:
      # Test composite uniqueness: employee appears once per simulation year
      - unique:
          column_name: "employee_id || '_' || simulation_year"
          name: "unique_employee_per_simulation_year"
      # Other data quality tests disabled for dbt 1.8.8 compatibility
    columns:
      - name: employee_id
        description: "Unique employee identifier within simulation year"
        data_type: varchar
        data_tests:
          - not_null
      - name: employee_ssn
        description: "Employee SSN identifier"
        data_type: varchar
        data_tests:
          - not_null
      - name: employee_birth_date
        description: "Employee birth date"
        data_type: timestamp
      - name: employee_hire_date
        description: "Employee hire date"
        data_type: timestamp
      - name: current_compensation
        description: "Current annual compensation"
        data_type: double
        data_tests:
          - not_null
          # **NEW COMPENSATION BOUNDS TESTS** - Comprehensive validation to prevent inflation issues
          # Critical bound: No compensation should exceed $10M
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 10000000
              config:
                severity: error
              name: "compensation_critical_upper_bound"
          # Warning bound: Flag compensation over $5M for review
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 5000000
              config:
                severity: warn
                where: "employment_status = 'active'"
              name: "compensation_warning_upper_bound"
          # Lower bound: Active employees should have reasonable compensation
          - dbt_utils.accepted_range:
              min_value: 10000
              max_value: 50000000
              config:
                where: "employment_status = 'active'"
              name: "active_compensation_reasonable_lower_bound"
      - name: prorated_annual_compensation
        description: "Prorated annual compensation based on actual time worked"
        data_type: double
      - name: full_year_equivalent_compensation
        description: "Full-year equivalent compensation eliminating proration effects"
        data_type: double
      - name: current_age
        description: "Current employee age"
        data_type: bigint
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 18
          #     max_value: 75
      - name: current_tenure
        description: "Current years of service"
        data_type: bigint
        data_tests:
          - not_null
          # Temporarily disabled to isolate DuckDBRelation serialization issue
          # - dbt_utils.accepted_range:
          #     min_value: 0
          #     max_value: 50
      - name: level_id
        description: "Current job level"
        data_type: integer
        data_tests:
          - not_null
          - accepted_values:
              values: [1, 2, 3, 4, 5]
      - name: age_band
        description: "Employee age band for analysis"
        data_type: varchar
      - name: tenure_band
        description: "Employee tenure band for analysis"
        data_type: varchar
      - name: employment_status
        description: "Current employment status"
        data_type: varchar
        data_tests:
          - not_null
          - accepted_values:
              values: ['active', 'terminated']
      - name: termination_date
        description: "Date of termination if applicable"
        data_type: timestamp
      - name: termination_reason
        description: "Reason for termination if applicable"
        data_type: varchar
      - name: detailed_status_code
        description: "Epic 11.5: Detailed status code categorizing employees into four cohorts"
        data_type: varchar
        data_tests:
          - not_null
          - accepted_values:
              values: ['continuous_active', 'experienced_termination', 'new_hire_active', 'new_hire_termination']
      - name: simulation_year
        description: "Simulation year for this snapshot"
        data_type: integer
        data_tests:
          - not_null
      - name: employee_eligibility_date
        description: "Date when employee becomes eligible for DC plan participation"
        data_type: date
      - name: waiting_period_days
        description: "Number of days employee must wait after hire to become eligible"
        data_type: integer
      - name: current_eligibility_status
        description: "Current eligibility status based on eligibility date and simulation year"
        data_type: varchar
        data_tests:
          - accepted_values:
              values: ['eligible', 'pending']
      - name: employee_enrollment_date
        description: "Date when employee enrolled in DC plan (from census data or enrollment events)"
        data_type: date
      - name: is_enrolled_flag
        description: "Whether employee is enrolled in DC plan"
        data_type: boolean
      - name: current_deferral_rate
        description: "Employee's current contribution deferral rate"
        data_type: decimal(5,4)
      # Epic E034: Employee contribution columns
      - name: prorated_annual_contributions
        description: "Prorated annual contribution amount based on employment periods"
        data_type: double
        data_tests:
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 50000
      - name: pre_tax_contributions
        description: "Pre-tax contribution portion (85% of total by default)"
        data_type: double
        data_tests:
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 50000
      - name: roth_contributions
        description: "Roth contribution portion (15% of total by default)"
        data_type: double
        data_tests:
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 50000
      - name: ytd_contributions
        description: "Year-to-date total contributions"
        data_type: double
        data_tests:
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 50000
      - name: irs_limit_reached
        description: "Whether employee has reached IRS 402(g) contribution limits"
        data_type: boolean
        data_tests:
          - not_null
      - name: effective_annual_deferral_rate
        description: "Effective annual deferral rate based on actual contributions"
        data_type: double
      - name: total_contribution_base_compensation
        description: "Total compensation used in contribution calculations"
        data_type: double
      - name: first_contribution_date
        description: "Date of first contribution in the year"
        data_type: date
      - name: last_contribution_date
        description: "Date of last contribution in the year"
        data_type: date
      - name: contribution_quality_flag
        description: "Data quality flag for contribution calculations"
        data_type: varchar
        data_tests:
          - accepted_values:
              values: ['NORMAL', 'HIGH_CONTRIBUTION_RATE', 'MULTIPLE_RATE_CHANGES', 'SHORT_CONTRIBUTION_PERIOD']
      - name: compensation_quality_flag
        description: "**E066 Enhanced** Compensation quality validation flag with annualization context"
        data_type: varchar
        data_tests:
          - not_null
          - accepted_values:
              values: ['NORMAL', 'WARNING_OVER_2M', 'WARNING_UNDER_10K', 'WARNING_ANNUALIZED_LATE_HIRE', 'WARNING_INFLATION_5X', 'SEVERE_OVER_5M', 'SEVERE_INFLATION_10X', 'CRITICAL_OVER_10M', 'CRITICAL_OVER_20M', 'CRITICAL_OVER_50M', 'CRITICAL_INFLATION_50X', 'CRITICAL_INFLATION_100X']
              config:
                severity: error
      - name: snapshot_created_at
        description: "Timestamp when snapshot was created"
        data_type: timestamp with time zone



  # Cross-model relationship tests
  - name: fct_compensation_growth
    description: "Compensation growth fact table validation"
    config:
      tags: ["critical"]
    # data_tests disabled for dbt 1.8.8 compatibility

# Note: Cross-table consistency tests are implemented in separate analysis models
# See data_quality_new_hire_termination_audit.sql and data_quality_event_sourcing_integrity.sql
