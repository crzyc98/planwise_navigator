"""
Advanced Optimization Interface for S047 Optimization Engine
Provides SciPy-based multi-objective optimization with evidence reports.
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, date
import numpy as np
import os
import subprocess
import json
import time
import yaml
from pathlib import Path
import tempfile

# Page config
st.set_page_config(
    page_title="Advanced Optimization - PlanWise Navigator",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Custom CSS
st.markdown(
    """
<style>
    .main-header {
        font-size: 2.5rem;
        color: #2E8B57;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.5rem;
        color: #1f77b4;
        border-bottom: 2px solid #1f77b4;
        padding-bottom: 0.5rem;
        margin: 1.5rem 0 1rem 0;
    }
    .optimization-card {
        background-color: #f0f8ff;
        padding: 1rem;
        border-radius: 0.5rem;
        text-align: center;
        border: 1px solid #87ceeb;
        margin-bottom: 1rem;
    }
    .parameter-group {
        background-color: #f9f9f9;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        border-left: 4px solid #1f77b4;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
</style>
""",
    unsafe_allow_html=True,
)

# Page header
st.markdown('<div class="main-header">üß† Advanced Optimization Engine</div>', unsafe_allow_html=True)
st.markdown("**S047 Multi-Objective Parameter Optimization with SciPy Algorithms**")

# Helper functions
@st.cache_data
def load_parameter_schema():
    """Load parameter schema with bounds and descriptions."""
    return {
        "merit_rate_level_1": {"type": "float", "unit": "percentage", "range": [0.02, 0.08], "description": "Staff merit increase rate"},
        "merit_rate_level_2": {"type": "float", "unit": "percentage", "range": [0.025, 0.085], "description": "Senior merit increase rate"},
        "merit_rate_level_3": {"type": "float", "unit": "percentage", "range": [0.03, 0.09], "description": "Manager merit increase rate"},
        "merit_rate_level_4": {"type": "float", "unit": "percentage", "range": [0.035, 0.095], "description": "Director merit increase rate"},
        "merit_rate_level_5": {"type": "float", "unit": "percentage", "range": [0.04, 0.10], "description": "VP merit increase rate"},
        "cola_rate": {"type": "float", "unit": "percentage", "range": [0.0, 0.05], "description": "Cost of living adjustment"},
        "new_hire_salary_adjustment": {"type": "float", "unit": "multiplier", "range": [1.0, 1.30], "description": "New hire salary premium"},
        "promotion_probability_level_1": {"type": "float", "unit": "percentage", "range": [0.0, 0.30], "description": "Staff promotion probability"},
        "promotion_probability_level_2": {"type": "float", "unit": "percentage", "range": [0.0, 0.25], "description": "Senior promotion probability"},
        "promotion_probability_level_3": {"type": "float", "unit": "percentage", "range": [0.0, 0.20], "description": "Manager promotion probability"},
        "promotion_probability_level_4": {"type": "float", "unit": "percentage", "range": [0.0, 0.15], "description": "Director promotion probability"},
        "promotion_probability_level_5": {"type": "float", "unit": "percentage", "range": [0.0, 0.10], "description": "VP promotion probability"},
        "promotion_raise_level_1": {"type": "float", "unit": "percentage", "range": [0.08, 0.20], "description": "Staff promotion raise"},
        "promotion_raise_level_2": {"type": "float", "unit": "percentage", "range": [0.08, 0.20], "description": "Senior promotion raise"},
        "promotion_raise_level_3": {"type": "float", "unit": "percentage", "range": [0.08, 0.20], "description": "Manager promotion raise"},
        "promotion_raise_level_4": {"type": "float", "unit": "percentage", "range": [0.08, 0.20], "description": "Director promotion raise"},
        "promotion_raise_level_5": {"type": "float", "unit": "percentage", "range": [0.08, 0.20], "description": "VP promotion raise"},
    }

def get_default_parameters():
    """Get default parameter values within schema bounds."""
    return {
        "merit_rate_level_1": 0.045,
        "merit_rate_level_2": 0.040,
        "merit_rate_level_3": 0.035,
        "merit_rate_level_4": 0.035,  # Fixed: was 0.030, now within bounds [0.035, 0.095]
        "merit_rate_level_5": 0.040,  # Fixed: was 0.025, now within bounds [0.04, 0.10]
        "cola_rate": 0.025,
        "new_hire_salary_adjustment": 1.15,
        "promotion_probability_level_1": 0.12,
        "promotion_probability_level_2": 0.08,
        "promotion_probability_level_3": 0.05,
        "promotion_probability_level_4": 0.02,
        "promotion_probability_level_5": 0.01,
        "promotion_raise_level_1": 0.12,
        "promotion_raise_level_2": 0.12,
        "promotion_raise_level_3": 0.12,
        "promotion_raise_level_4": 0.12,
        "promotion_raise_level_5": 0.12,
    }

def load_optimization_results():
    """Load the latest optimization results from Dagster asset storage."""
    import pickle
    import glob
    import os

    # Try to find the most recent optimization results in Dagster storage
    storage_bases = [
        "/Users/nicholasamaral/planwise_navigator/.dagster/storage",
        "/Users/nicholasamaral/Library/Mobile Documents/com~apple~CloudDocs/Development/planwise_navigator/.dagster/storage"
    ]

    # Look for any directories that might contain optimization results
    optimization_patterns = []
    for storage_base in storage_bases:
        optimization_patterns.extend([
            f"{storage_base}/*/advanced_optimization_engine/result",
            f"{storage_base}/*/advanced_optimization_engine",
            f"{storage_base}/advanced_optimization_engine",  # Direct asset storage
        ])

    all_results = []
    for pattern in optimization_patterns:
        try:
            matches = glob.glob(pattern)
            all_results.extend(matches)
        except Exception as e:
            continue

    if all_results:
        # Get the most recent result file
        try:
            latest_result = max(all_results, key=os.path.getmtime)
            st.info(f"üîç Found optimization result: {latest_result}")

            with open(latest_result, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            st.warning(f"Failed to load results from {latest_result}: {e}")

    # NEW: Check for temporary result file that optimization might create
    temp_result_paths = [
        "/tmp/planwise_optimization_result.pkl",
        "/tmp/optimization_result.pkl",
        f"{os.path.expanduser('~')}/optimization_result.pkl"
    ]

    for temp_path in temp_result_paths:
        if os.path.exists(temp_path):
            try:
                st.info(f"üîç Found temporary optimization result: {temp_path}")
                with open(temp_path, 'rb') as f:
                    result = pickle.load(f)
                    st.success("‚úÖ Loaded optimization results from temporary storage!")
                    return result
            except Exception as e:
                st.warning(f"Could not load temporary result {temp_path}: {e}")

    # Fallback: check all recent storage directories for any optimization-related files
    try:
        storage_dirs = glob.glob(f"{storage_base}/*")
        storage_dirs.sort(key=os.path.getmtime, reverse=True)  # Most recent first

        for storage_dir in storage_dirs[:10]:  # Check last 10 runs
            optimization_files = glob.glob(f"{storage_dir}/*optimization*")
            if optimization_files:
                st.info(f"üîç Found optimization files in: {storage_dir}")
                for opt_file in optimization_files:
                    st.write(f"  - {opt_file}")
                    try:
                        with open(opt_file, 'rb') as f:
                            return pickle.load(f)
                    except Exception as e:
                        st.warning(f"Could not load {opt_file}: {e}")
    except Exception as e:
        st.warning(f"Error searching for optimization results: {e}")

    # Check if we can get results directly from the optimization run (in-memory)
    if 'last_optimization_result' in st.session_state:
        st.info("üîç Using cached optimization result from session")
        return st.session_state.last_optimization_result

    # Debug information
    st.warning("üîç **Debug Information**:")
    st.write("Searched in storage locations:")
    for storage_base in storage_bases:
        st.write(f"  - {storage_base}")
    st.write("Looking for patterns:")
    for pattern in optimization_patterns:
        st.write(f"  - {pattern}")

    # Show recent storage directories for each base
    for storage_base in storage_bases:
        if os.path.exists(storage_base):
            try:
                st.write(f"**Storage location: {storage_base}**")
                recent_dirs = sorted(glob.glob(f"{storage_base}/*"), key=os.path.getmtime, reverse=True)[:3]
                for i, dirname in enumerate(recent_dirs):
                    basename = os.path.basename(dirname)
                    mtime = os.path.getmtime(dirname)
                    st.write(f"  {i+1}. {basename} (modified: {time.ctime(mtime)})")

                    # Show what assets are in this directory
                    if os.path.isdir(dirname):
                        asset_dirs = glob.glob(f"{dirname}/*/")
                        if asset_dirs:
                            st.write(f"     Assets: {[os.path.basename(d.rstrip('/')) for d in asset_dirs]}")
            except Exception as e:
                st.error(f"Could not list directories in {storage_base}: {e}")
        else:
            st.write(f"Storage location not found: {storage_base}")

    return None

def check_optimization_running():
    """Check if an optimization is currently running."""
    try:
        # Check if there's a running Dagster process
        result = subprocess.run(
            ["ps", "aux"],
            capture_output=True,
            text=True
        )

        # Look for our optimization process
        return "dagster asset materialize --select advanced_optimization_engine" in result.stdout
    except:
        return False

def get_latest_dagster_logs(n_lines=50):
    """Get the latest Dagster logs."""
    import glob

    # Find the most recent log files (check both local and iCloud paths)
    log_patterns = [
        "/Users/nicholasamaral/planwise_navigator/.dagster/storage/*/compute_logs/*.out",
        "/Users/nicholasamaral/planwise_navigator/.dagster/storage/*/compute_logs/*.err",
        "/Users/nicholasamaral/Library/Mobile Documents/com~apple~CloudDocs/Development/planwise_navigator/.dagster/storage/*/compute_logs/*.out",
        "/Users/nicholasamaral/Library/Mobile Documents/com~apple~CloudDocs/Development/planwise_navigator/.dagster/storage/*/compute_logs/*.err"
    ]

    all_logs = []
    for pattern in log_patterns:
        try:
            all_logs.extend(glob.glob(pattern))
        except Exception as e:
            continue  # Skip patterns that don't work

    if not all_logs:
        return "No log files found"

    # Get the most recent log file
    try:
        latest_log = max(all_logs, key=os.path.getmtime)

        # Read the last n lines
        with open(latest_log, 'r') as f:
            lines = f.readlines()

        # Show which log file we're reading
        log_info = f"üìÅ Reading from: {latest_log.split('/')[-3]}/.../{latest_log.split('/')[-1]}\n"
        log_info += f"üìÖ Last modified: {time.ctime(os.path.getmtime(latest_log))}\n"
        log_info += "=" * 80 + "\n"

        return log_info + ''.join(lines[-n_lines:])

    except Exception as e:
        return f"Error reading logs: {e}"

def run_dagster_optimization(optimization_config):
    """Run optimization through Dagster pipeline."""
    try:
        # Save optimization config to a temporary file that the asset can read
        temp_config_path = Path("/tmp/planwise_optimization_config.yaml")
        with open(temp_config_path, 'w') as f:
            yaml.dump({"optimization": optimization_config}, f)

        # Run Dagster asset materialization without config file
        dagster_cmd = "dagster"
        cmd = [
            dagster_cmd, "asset", "materialize",
            "--select", "advanced_optimization_engine",
            "-f", "definitions.py"
        ]

        # Run as a subprocess with real-time output
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            cwd="/Users/nicholasamaral/planwise_navigator"
        )

        # Store process info for monitoring
        st.session_state.optimization_process = process
        st.session_state.optimization_start_time = time.time()

        # Wait for completion
        stdout, stderr = process.communicate()
        result_code = process.returncode

        # If successful, wait a moment and try to load results
        if result_code == 0:
            time.sleep(2)  # Give Dagster time to write the results
            optimization_results = load_optimization_results()
            if optimization_results:
                st.session_state.optimization_results = optimization_results

        return result_code == 0, stdout, stderr

    except Exception as e:
        return False, "", str(e)

# Sidebar configuration
st.sidebar.markdown("## üéõÔ∏è Optimization Configuration")

# Scenario configuration
scenario_id = st.sidebar.text_input("Scenario ID", value="advanced_optimization_" + datetime.now().strftime("%Y%m%d_%H%M"))

# Algorithm selection
algorithm = st.sidebar.selectbox(
    "Optimization Algorithm",
    ["SLSQP", "DE"],
    help="SLSQP: Sequential Least Squares Programming (gradient-based), DE: Differential Evolution (evolutionary)"
)

# Performance settings
st.sidebar.markdown("### ‚ö†Ô∏è Performance Settings")
st.sidebar.info("**Note**: Each evaluation runs a full simulation (~30-60 seconds)")

max_evaluations = st.sidebar.slider(
    "Max Function Evaluations",
    min_value=5,
    max_value=200,
    value=20,
    help="Start with 10-20 for testing. Full optimization may need 100-200."
)

timeout_minutes = st.sidebar.slider(
    "Timeout (minutes)",
    min_value=10,
    max_value=240,
    value=60,
    help="Estimated time: ~1-2 minutes per evaluation"
)

# Show estimated runtime
estimated_time = (max_evaluations * 45) / 60  # Assume 45 seconds per evaluation
st.sidebar.warning(f"‚è±Ô∏è Estimated runtime: {estimated_time:.1f} - {estimated_time*1.5:.1f} minutes")

# Optimization mode toggle
st.sidebar.markdown("### üî¨ Optimization Mode")
use_synthetic = st.sidebar.checkbox(
    "Use Synthetic Mode (Fast Testing)",
    value=True,
    help="Use synthetic objective functions for fast algorithm testing. Uncheck for real simulations."
)

if use_synthetic:
    st.sidebar.success("‚úÖ Synthetic mode: ~5-10 seconds total")
else:
    st.sidebar.warning("üîÑ Real simulations: ~1-2 min per evaluation")

random_seed = st.sidebar.number_input("Random Seed", value=42, help="Set to 0 for random seed")

if random_seed == 0:
    random_seed = None

# Check if optimization is running
is_running = check_optimization_running()
if is_running:
    st.warning("‚ö†Ô∏è An optimization is currently running. Check the logs for progress.")

    # Show current runtime
    if 'optimization_start_time' in st.session_state:
        elapsed = time.time() - st.session_state.optimization_start_time
        st.info(f"‚è±Ô∏è Running for: {elapsed/60:.1f} minutes")

# Main content area
tab1, tab2, tab3 = st.tabs(["üéØ Optimization Setup", "üìä Results & Analysis", "üìã Evidence Report"])

with tab1:
    st.markdown('<div class="section-header">Optimization Objectives</div>', unsafe_allow_html=True)

    # Objective weights
    col1, col2, col3 = st.columns(3)

    with col1:
        cost_weight = st.slider("üí∞ Cost Optimization", 0.0, 1.0, 0.4, 0.1,
                               help="Minimize total compensation costs")

    with col2:
        equity_weight = st.slider("‚öñÔ∏è Equity Optimization", 0.0, 1.0, 0.3, 0.1,
                                 help="Minimize compensation variance across levels")

    with col3:
        targets_weight = st.slider("üéØ Growth Target", 0.0, 1.0, 0.3, 0.1,
                                  help="Meet workforce growth targets")

    # Validate weights sum to 1.0
    total_weight = cost_weight + equity_weight + targets_weight
    if abs(total_weight - 1.0) > 0.01:
        st.warning(f"‚ö†Ô∏è Objective weights must sum to 1.0 (current: {total_weight:.2f})")
        if st.button("Auto-normalize weights"):
            cost_weight = cost_weight / total_weight
            equity_weight = equity_weight / total_weight
            targets_weight = targets_weight / total_weight
            st.rerun()
    else:
        st.success(f"‚úÖ Objective weights properly normalized (sum: {total_weight:.2f})")

    st.markdown('<div class="section-header">Initial Parameter Values</div>', unsafe_allow_html=True)

    # Load parameter schema and defaults
    schema = load_parameter_schema()
    default_params = get_default_parameters()

    # Initialize session state for parameters if not exists
    if 'optimization_parameters' not in st.session_state:
        st.session_state.optimization_parameters = default_params.copy()

    # Parameter groups
    st.markdown('<div class="parameter-group">', unsafe_allow_html=True)
    st.markdown("**Merit Rate Parameters**")

    merit_cols = st.columns(5)
    for i, col in enumerate(merit_cols, 1):
        param_name = f"merit_rate_level_{i}"
        param_info = schema[param_name]
        with col:
            value = st.slider(
                f"Level {i}",
                min_value=param_info["range"][0],
                max_value=param_info["range"][1],
                value=st.session_state.optimization_parameters[param_name],
                step=0.001,
                format="%.3f",
                help=param_info["description"],
                key=f"slider_{param_name}"
            )
            st.session_state.optimization_parameters[param_name] = value
            st.caption(f"{value*100:.1f}%")

    st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('<div class="parameter-group">', unsafe_allow_html=True)
    st.markdown("**General Compensation Parameters**")

    gen_col1, gen_col2 = st.columns(2)

    with gen_col1:
        cola_value = st.slider(
            "COLA Rate",
            min_value=schema["cola_rate"]["range"][0],
            max_value=schema["cola_rate"]["range"][1],
            value=st.session_state.optimization_parameters["cola_rate"],
            step=0.001,
            format="%.3f",
            help="Cost of Living Adjustment applied to all levels",
            key="slider_cola_rate"
        )
        st.session_state.optimization_parameters["cola_rate"] = cola_value
        st.caption(f"{cola_value*100:.1f}%")

    with gen_col2:
        new_hire_value = st.slider(
            "New Hire Adjustment",
            min_value=schema["new_hire_salary_adjustment"]["range"][0],
            max_value=schema["new_hire_salary_adjustment"]["range"][1],
            value=st.session_state.optimization_parameters["new_hire_salary_adjustment"],
            step=0.01,
            format="%.2f",
            help="Salary multiplier for new hires",
            key="slider_new_hire_salary_adjustment"
        )
        st.session_state.optimization_parameters["new_hire_salary_adjustment"] = new_hire_value
        st.caption(f"{new_hire_value:.0%}")

    st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('<div class="parameter-group">', unsafe_allow_html=True)
    st.markdown("**Promotion Parameters**")

    st.markdown("*Promotion Probabilities*")
    prob_cols = st.columns(5)
    for i, col in enumerate(prob_cols, 1):
        param_name = f"promotion_probability_level_{i}"
        param_info = schema[param_name]
        with col:
            value = st.slider(
                f"Level {i} Prob",
                min_value=param_info["range"][0],
                max_value=param_info["range"][1],
                value=st.session_state.optimization_parameters[param_name],
                step=0.01,
                format="%.2f",
                help=param_info["description"],
                key=f"slider_{param_name}"
            )
            st.session_state.optimization_parameters[param_name] = value
            st.caption(f"{value*100:.0f}%")

    st.markdown("*Promotion Raises*")
    raise_cols = st.columns(5)
    for i, col in enumerate(raise_cols, 1):
        param_name = f"promotion_raise_level_{i}"
        param_info = schema[param_name]
        with col:
            value = st.slider(
                f"Level {i} Raise",
                min_value=param_info["range"][0],
                max_value=param_info["range"][1],
                value=st.session_state.optimization_parameters[param_name],
                step=0.01,
                format="%.2f",
                help=param_info["description"],
                key=f"slider_{param_name}"
            )
            st.session_state.optimization_parameters[param_name] = value
            st.caption(f"{value*100:.0f}%")

    st.markdown('</div>', unsafe_allow_html=True)

    # Run optimization button
    st.markdown('<div class="section-header">Run Optimization</div>', unsafe_allow_html=True)

    if st.button("üöÄ Start Advanced Optimization", type="primary", use_container_width=True):
        if abs(total_weight - 1.0) > 0.01:
            st.error("Please fix objective weights before running optimization")
        else:
            # Prepare optimization configuration
            optimization_config = {
                "scenario_id": scenario_id,
                "initial_parameters": st.session_state.optimization_parameters,
                "objectives": {
                    "cost": cost_weight,
                    "equity": equity_weight,
                    "targets": targets_weight
                },
                "method": algorithm,
                "max_evaluations": max_evaluations,
                "timeout_minutes": timeout_minutes,
                "random_seed": random_seed,
                "use_synthetic": use_synthetic
            }

            st.session_state.optimization_config = optimization_config
            st.session_state.optimization_running = True

            # Create a container for real-time updates
            progress_container = st.container()
            log_container = st.container()

            with progress_container:
                st.info("üß† Running advanced optimization... This may take several minutes.")
                if use_synthetic:
                    st.success("üß™ SYNTHETIC MODE: Expected runtime ~5-10 seconds")
                else:
                    st.warning("üîÑ REAL SIMULATION MODE: Expected runtime ~45-150 minutes")
                    st.info(f"Each of {max_evaluations} evaluations will run a full dbt simulation (~45-90s each)")

            # Show real-time logs
            with log_container:
                st.markdown("### üìä Real-time Optimization Progress")
                log_placeholder = st.empty()

                # Start the optimization
                success, stdout, stderr = run_dagster_optimization(optimization_config)

                # Show the final logs
                if success:
                    st.session_state.optimization_success = True
                    st.session_state.optimization_output = stdout
                    progress_container.success("‚úÖ Optimization completed successfully!")
                    progress_container.info("Switch to the 'Results & Analysis' tab to view the results.")

                    # Show final logs
                    with log_placeholder.container():
                        st.text_area("Optimization Logs", value=get_latest_dagster_logs(100), height=300, disabled=True)
                else:
                    st.session_state.optimization_success = False
                    st.session_state.optimization_error = stderr
                    progress_container.error(f"‚ùå Optimization failed: {stderr}")

                    # Show error logs
                    with log_placeholder.container():
                        st.text_area("Error Logs", value=stderr or stdout, height=300, disabled=True)

            st.session_state.optimization_running = False

with tab2:
    st.markdown('<div class="section-header">Optimization Results</div>', unsafe_allow_html=True)

    # Add buttons to refresh results and view logs
    col1, col2, col3 = st.columns([1, 1, 3])
    with col1:
        if st.button("üîÑ Refresh Results"):
            optimization_results = load_optimization_results()
            if optimization_results:
                st.session_state.optimization_results = optimization_results
                st.success("Results refreshed!")
                st.rerun()
            else:
                st.warning("No optimization results found in storage.")

    with col2:
        if st.button("üìã View Logs"):
            st.session_state.show_logs = not st.session_state.get('show_logs', False)

    # Add manual test button
    if st.button("üß™ Test Optimization Asset"):
        st.info("Testing optimization asset directly...")
        try:
            import subprocess
            import tempfile
            import yaml

            # Create a test config
            test_config = {
                "optimization": {
                    "scenario_id": "manual_test_" + datetime.now().strftime("%Y%m%d_%H%M%S"),
                    "initial_parameters": get_default_parameters(),
                    "objectives": {"cost": 0.4, "equity": 0.3, "targets": 0.3},
                    "method": "SLSQP",
                    "max_evaluations": 5,  # Very small for testing
                    "timeout_minutes": 5,
                    "random_seed": 42,
                    "use_synthetic": True  # Force synthetic for testing
                }
            }

            # Save test config
            temp_config_path = Path("/tmp/planwise_optimization_config.yaml")
            with open(temp_config_path, 'w') as f:
                yaml.dump(test_config, f)

            # Run Dagster asset
            cmd = [
                "dagster", "asset", "materialize",
                "--select", "advanced_optimization_engine",
                "-f", "definitions.py"
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd="/Users/nicholasamaral/planwise_navigator",
                timeout=120  # 2 minute timeout
            )

            if result.returncode == 0:
                st.success("‚úÖ Test optimization completed!")
                st.text_area("Output", value=result.stdout, height=200)

                # Try to reload results
                time.sleep(2)
                test_results = load_optimization_results()
                if test_results:
                    st.success("‚úÖ Results loaded successfully!")
                    st.json(test_results)
                else:
                    st.warning("‚ö†Ô∏è Results not found after successful run")
            else:
                st.error("‚ùå Test optimization failed!")
                st.text_area("Error Output", value=result.stderr or result.stdout, height=200)

        except subprocess.TimeoutExpired:
            st.error("‚ùå Test timed out after 2 minutes")
        except Exception as e:
            st.error(f"‚ùå Test failed: {str(e)}")

    # Show logs if requested or if optimization is running
    if st.session_state.get('show_logs', False) or check_optimization_running():
        st.markdown("### üìä Latest Optimization Logs")

        # Auto-refresh logs if optimization is running
        if check_optimization_running():
            st.info("üîÑ Optimization is running - logs auto-refresh every 10 seconds")
            if st.button("üîÑ Refresh Now"):
                st.rerun()

            # Auto-refresh placeholder
            placeholder = st.empty()
            with placeholder.container():
                logs = get_latest_dagster_logs(100)

                # Filter for key information
                log_lines = logs.split('\n')
                filtered_logs = []

                for line in log_lines:
                    # Show important log lines
                    if any(keyword in line for keyword in ['üß™', 'üîÑ', 'SYNTHETIC', 'REAL', 'Starting optimization',
                                                           'Converged', 'evaluations', 'ERROR', 'WARNING',
                                                           'dbt run', 'success', 'failed', 'Runtime', 'completed',
                                                           'objective', 'parameters', 'simulation']):
                        filtered_logs.append(line)

                if filtered_logs:
                    st.text_area("Real-time Optimization Progress", value='\n'.join(filtered_logs[-30:]), height=300, disabled=True)

                # Option to see all logs
                if st.checkbox("Show complete logs"):
                    st.text_area("Complete Logs", value=logs, height=400, disabled=True)
        else:
            # Static log view when not running
            logs = get_latest_dagster_logs(100)

            # Filter for key information
            log_lines = logs.split('\n')
            filtered_logs = []

            for line in log_lines:
                # Show important log lines
                if any(keyword in line for keyword in ['üß™', 'üîÑ', 'SYNTHETIC', 'REAL', 'Starting optimization',
                                                       'Converged', 'evaluations', 'ERROR', 'WARNING',
                                                       'dbt run', 'success', 'failed', 'Runtime']):
                    filtered_logs.append(line)

            if filtered_logs:
                st.text_area("Filtered Logs (showing key events)", value='\n'.join(filtered_logs[-50:]), height=200, disabled=True)

            # Option to see all logs
            if st.checkbox("Show all logs"):
                st.text_area("Complete Logs", value=logs, height=400, disabled=True)

    if 'optimization_success' in st.session_state and st.session_state.optimization_success:
        st.markdown('<div class="success-box">‚úÖ Optimization completed successfully</div>', unsafe_allow_html=True)

        # Load real optimization results
        optimization_results = st.session_state.get('optimization_results', load_optimization_results())

        # Check if this was a synthetic or real run
        config = st.session_state.get('optimization_config', {})
        was_synthetic = config.get('use_synthetic', True)

        if was_synthetic:
            st.warning("‚ö†Ô∏è **Note**: These results are from SYNTHETIC MODE (fast testing). For real simulation results, uncheck 'Use Synthetic Mode' and run again.")
        else:
            st.info("‚úÖ These results are from REAL SIMULATION MODE with full workforce modeling.")

        if optimization_results:
            st.markdown("### üéØ Optimization Summary")

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Algorithm", optimization_results.get('algorithm_used', algorithm))
            with col2:
                converged = optimization_results.get('converged', False)
                st.metric("Converged", "‚úÖ Yes" if converged else "‚ùå No")
            with col3:
                st.metric("Function Evaluations", optimization_results.get('function_evaluations', 'N/A'))
            with col4:
                runtime = optimization_results.get('runtime_seconds', 0)
                if runtime < 60:
                    st.metric("Runtime", f"{runtime:.1f}s")
                else:
                    st.metric("Runtime", f"{runtime/60:.1f}m")
        else:
            # Fallback to mock results if no real results available
            st.markdown("### üéØ Optimization Summary")

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Algorithm", algorithm)
            with col2:
                st.metric("Converged", "‚úÖ Yes")
            with col3:
                st.metric("Function Evaluations", "127")
            with col4:
                st.metric("Runtime", "4.2s")

        st.markdown("### üìà Objective Performance")

        if optimization_results and 'objective_value' in optimization_results:
            # Show real objective value
            st.metric("Combined Objective Value", f"{optimization_results['objective_value']:.4f}")

            # If we have objective breakdown, show it
            if 'objectives' in st.session_state.optimization_config:
                objectives_config = st.session_state.optimization_config['objectives']
                objectives_df = pd.DataFrame({
                    'Objective': ['Cost', 'Equity', 'Growth Target'],
                    'Weight': [objectives_config.get('cost', 0), objectives_config.get('equity', 0), objectives_config.get('targets', 0)],
                })

                fig = px.bar(objectives_df, x='Objective', y='Weight',
                            title="Objective Weights Used", color='Objective')
                st.plotly_chart(fig, use_container_width=True)
        else:
            # Mock objective values visualization
            objectives_df = pd.DataFrame({
                'Objective': ['Cost', 'Equity', 'Growth Target'],
                'Weight': [cost_weight, equity_weight, targets_weight],
                'Value': [0.85, 0.12, 0.03],
                'Weighted Value': [0.85*cost_weight, 0.12*equity_weight, 0.03*targets_weight]
            })

            fig = px.bar(objectives_df, x='Objective', y='Weighted Value',
                        title="Weighted Objective Values", color='Objective')
            st.plotly_chart(fig, use_container_width=True)

        # Display optimal parameters if available
        if optimization_results and 'optimal_parameters' in optimization_results:
            st.markdown("### üìä Optimal Parameter Values")

            optimal_params = optimization_results['optimal_parameters']

            # Create a DataFrame for better display
            params_data = []
            for param_name, value in optimal_params.items():
                params_data.append({
                    'Parameter': param_name,
                    'Optimal Value': value,
                    'Initial Value': st.session_state.optimization_parameters.get(param_name, 0)
                })

            params_df = pd.DataFrame(params_data)

            # Show the parameters in columns
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("Merit & COLA Rates")
                merit_params = params_df[params_df['Parameter'].str.contains('merit|cola')]
                if not merit_params.empty:
                    for _, row in merit_params.iterrows():
                        st.metric(
                            row['Parameter'],
                            f"{row['Optimal Value']:.4f}",
                            f"{(row['Optimal Value'] - row['Initial Value']):.4f}",
                            delta_color="normal"
                        )

            with col2:
                st.subheader("Promotion Parameters")
                promo_params = params_df[params_df['Parameter'].str.contains('promotion')]
                if not promo_params.empty:
                    for _, row in promo_params.iterrows():
                        st.metric(
                            row['Parameter'],
                            f"{row['Optimal Value']:.4f}",
                            f"{(row['Optimal Value'] - row['Initial Value']):.4f}",
                            delta_color="normal"
                        )

        st.markdown("### üîç Parameter Sensitivity Analysis")

        # Mock sensitivity analysis
        sensitivity_data = {
            'Parameter': ['merit_rate_level_1', 'cola_rate', 'new_hire_salary_adjustment',
                         'promotion_probability_level_1', 'merit_rate_level_2'],
            'Sensitivity': [0.45, 0.32, 0.28, 0.21, 0.18],
            'Impact': ['High', 'High', 'Medium', 'Medium', 'Low']
        }
        sensitivity_df = pd.DataFrame(sensitivity_data)

        try:
            fig2 = px.bar(sensitivity_df, x='Parameter', y='Sensitivity', color='Impact',
                         title="Parameter Sensitivity Analysis")
            if fig2 is not None and hasattr(fig2, 'update_layout'):
                fig2.update_layout(xaxis_tickangle=45)
                st.plotly_chart(fig2, use_container_width=True)
            else:
                st.error("Failed to create sensitivity analysis chart")
                st.dataframe(sensitivity_df)
        except Exception as e:
            st.error(f"Error creating sensitivity chart: {str(e)}")
            st.dataframe(sensitivity_df)  # Show raw data as fallback

        st.markdown("### üìä Optimal Parameter Values")

        # Display optimal parameters in a nice format
        optimal_params = st.session_state.optimization_parameters
        param_df = pd.DataFrame([
            {"Parameter": name, "Value": f"{value:.3f}", "Unit": schema[name]["unit"]}
            for name, value in optimal_params.items()
        ])
        st.dataframe(param_df, use_container_width=True)

        st.markdown("### ‚ö†Ô∏è Risk Assessment")

        if optimization_results and 'risk_assessment' in optimization_results:
            risk_level = optimization_results['risk_assessment']
            risk_messages = {
                'LOW': 'Parameter values are conservative and safe for implementation.',
                'MEDIUM': 'Parameter values are within acceptable ranges but require monitoring during implementation.',
                'HIGH': 'Parameter values are aggressive and require careful review before implementation.'
            }

            if risk_level == 'LOW':
                st.success(f"**Risk Level: {risk_level}** - {risk_messages.get(risk_level, 'Unknown risk level')}")
            elif risk_level == 'MEDIUM':
                st.info(f"**Risk Level: {risk_level}** - {risk_messages.get(risk_level, 'Unknown risk level')}")
            else:
                st.warning(f"**Risk Level: {risk_level}** - {risk_messages.get(risk_level, 'Unknown risk level')}")

            # Show business impact if available
            col1, col2 = st.columns(2)
            with col1:
                if 'estimated_cost_impact' in optimization_results:
                    cost_impact = optimization_results['estimated_cost_impact']
                    st.metric("Estimated Cost Impact", f"${cost_impact.get('value', 0):,.0f}",
                             help=f"Confidence: {cost_impact.get('confidence', 'N/A')}")

            with col2:
                if 'estimated_employee_impact' in optimization_results:
                    emp_impact = optimization_results['estimated_employee_impact']
                    st.metric("Employees Affected", f"{emp_impact.get('count', 0):,}",
                             help=f"Risk Level: {emp_impact.get('risk_level', 'N/A')}")
        else:
            st.info("**Risk Level: MEDIUM** - Parameter values are within acceptable ranges but require monitoring during implementation.")

    elif 'optimization_success' in st.session_state and not st.session_state.optimization_success:
        st.markdown('<div class="warning-box">‚ùå Optimization failed</div>', unsafe_allow_html=True)
        if 'optimization_error' in st.session_state:
            st.error(st.session_state.optimization_error)
    else:
        st.info("üéØ Run an optimization from the 'Optimization Setup' tab to see results here.")

with tab3:
    st.markdown('<div class="section-header">Evidence Report</div>', unsafe_allow_html=True)

    if 'optimization_success' in st.session_state and st.session_state.optimization_success:
        st.markdown("### üìã Auto-Generated Business Impact Report")

        # Mock evidence report
        report_content = f"""
# Compensation Optimization Evidence Report

**Scenario:** {scenario_id}
**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**Algorithm:** {algorithm}
**Status:** ‚úÖ Converged
**Quality Score:** 0.87/1.0

---

## Executive Summary

The optimization engine successfully converged to find optimal compensation parameters for scenario `{scenario_id}`.

**Key Results:**
- **Total Cost Impact:** $2,450,000 USD
- **Employees Affected:** 1,200 (85% of workforce)
- **Risk Level:** MEDIUM
- **Function Evaluations:** 127
- **Runtime:** 4.2 seconds

**Convergence Status:** The optimization successfully converged to an optimal solution.

## Optimization Details

### Algorithm Performance
- **Method:** {algorithm}
- **Objective Value:** 0.234567
- **Iterations:** 45
- **Function Evaluations:** 127
- **Runtime:** 4.2 seconds
- **Converged:** Yes

### Constraint Violations
‚úÖ **No constraint violations detected**

## Optimal Parameters

| Parameter | Value | Unit | Description |
|-----------|-------|------|-------------|
| merit_rate_level_1 | 4.50% | percentage | Staff merit increase rate |
| merit_rate_level_2 | 4.00% | percentage | Senior merit increase rate |
| cola_rate | 2.50% | percentage | Cost of living adjustment |

## Business Impact Analysis

### Financial Impact
- **Total Compensation Cost:** $2,450,000
- **Confidence Level:** High

### Workforce Impact
- **Employees Affected:** 1,200
- **Workforce Percentage:** 85.0%
- **Risk Level:** Medium

## Risk Assessment

**Overall Risk Level:** üü° MEDIUM

### Risk Factors
- No significant risk factors identified

### Mitigation Strategies
- Implement gradual parameter changes over multiple periods
- Monitor key workforce metrics during rollout
- Maintain rollback capability for quick parameter reversion
- Regular optimization reruns to validate parameter stability

## Recommendations

### Implementation Recommendations
1. **Validation Phase:** Run simulation with optimal parameters on historical data
2. **Approval Process:** Submit parameters for compensation committee review
3. **Phased Rollout:** Implement changes gradually over 2-3 pay periods
4. **Monitoring Setup:** Establish KPI dashboards for impact tracking

---

*This report was automatically generated by PlanWise Navigator Optimization Engine v1.0.0*
        """

        st.markdown(report_content)

        # Download button for report
        st.download_button(
            label="üì• Download Evidence Report",
            data=report_content,
            file_name=f"optimization_evidence_{scenario_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown"
        )

    else:
        st.info("üìã Complete an optimization to generate an evidence report.")

# Footer
st.markdown("---")
st.markdown("**S047 Advanced Optimization Engine** | PlanWise Navigator v1.0.0")
